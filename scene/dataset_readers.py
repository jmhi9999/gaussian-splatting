import os
import sys
import numpy as np
import cv2
import torch
from pathlib import Path
import json
from scipy.optimize import least_squares
from PIL import Image
from typing import NamedTuple
import glob

# ê¸°ì¡´ 3DGS imports
from scene.colmap_loader import read_extrinsics_text, read_intrinsics_text, qvec2rotmat, \
    read_extrinsics_binary, read_intrinsics_binary, read_points3D_binary, read_points3D_text
from utils.graphics_utils import getWorld2View2, focal2fov, fov2focal, BasicPointCloud
from plyfile import PlyData, PlyElement
from utils.sh_utils import SH2RGB

# ê¸°ì¡´ íƒ€ì…ë“¤
class CameraInfo(NamedTuple):
    uid: int
    R: np.array
    T: np.array
    FovY: np.array
    FovX: np.array
    depth_params: dict
    image_path: str
    image_name: str
    depth_path: str
    width: int
    height: int
    is_test: bool

class SceneInfo(NamedTuple):
    point_cloud: BasicPointCloud
    train_cameras: list
    test_cameras: list
    nerf_normalization: dict
    ply_path: str
    is_nerf_synthetic: bool


# SuperGlue ëª¨ë“ˆ ê²½ë¡œ ìˆ˜ì •
def import_superglue_pipeline():
    """SuperGlue íŒŒì´í”„ë¼ì¸ ë™ì  import"""
    try:
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ SuperGlue ê²½ë¡œ ì°¾ê¸°
        current_dir = Path(__file__).parent.parent  # gaussian-splatting ë£¨íŠ¸
        
        # SuperGlue ê²½ë¡œë“¤
        superglue_paths = [
            current_dir / "Superglue",
            current_dir / "SuperGlue", 
            current_dir
        ]
        
        for path in superglue_paths:
            complete_sfm_file = path / "complete_superglue_sfm.py"
            if complete_sfm_file.exists():
                # í•´ë‹¹ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
                sys.path.insert(0, str(path))
                
                # ëª¨ë“ˆ import
                from complete_superglue_sfm import SuperGlue3DGSPipeline
                print(f"âœ“ SuperGlue pipeline imported from {path}")
                return SuperGlue3DGSPipeline
        
        print("âœ— SuperGlue pipeline not found")
        return None
        
    except ImportError as e:
        print(f"âœ— SuperGlue import failed: {e}")
        return None

def import_superglue_colmap_hybrid():
    """SuperGlue + COLMAP í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸ ë™ì  import"""
    try:
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ SuperGlue ê²½ë¡œ ì°¾ê¸°
        current_dir = Path(__file__).parent.parent  # gaussian-splatting ë£¨íŠ¸
        
        # SuperGlue ê²½ë¡œë“¤
        superglue_paths = [
            current_dir / "Superglue",
            current_dir / "SuperGlue", 
            current_dir
        ]
        
        for path in superglue_paths:
            hybrid_file = path / "superglue_colmap_hybrid.py"
            if hybrid_file.exists():
                # í•´ë‹¹ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
                sys.path.insert(0, str(path))
                
                # ëª¨ë“ˆ import
                from superglue_colmap_hybrid import SuperGlueCOLMAPHybrid
                print(f"âœ“ SuperGlue + COLMAP hybrid pipeline imported from {path}")
                return SuperGlueCOLMAPHybrid
        
        print("âœ— SuperGlue + COLMAP hybrid pipeline not found")
        return None
        
    except ImportError as e:
        print(f"âœ— SuperGlue + COLMAP hybrid import failed: {e}")
        return None

# SuperGlue íŒŒì´í”„ë¼ì¸ import ì‹œë„
SuperGlue3DGSPipeline = import_superglue_pipeline()
SUPERGLUE_PIPELINE_AVAILABLE = (SuperGlue3DGSPipeline is not None)

# SuperGlue + COLMAP í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸ import ì‹œë„
SuperGlueCOLMAPHybrid = import_superglue_colmap_hybrid()
SUPERGLUE_COLMAP_HYBRID_AVAILABLE = (SuperGlueCOLMAPHybrid is not None)

# Hloc íŒŒì´í”„ë¼ì¸ import ì‹œë„
def import_hloc_pipeline():
    """Hloc íŒŒì´í”„ë¼ì¸ ë™ì  import"""
    try:
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ SuperGlue ê²½ë¡œ ì°¾ê¸°
        current_dir = Path(__file__).parent.parent  # gaussian-splatting ë£¨íŠ¸
        
        # SuperGlue ê²½ë¡œë“¤
        superglue_paths = [
            current_dir / "Superglue",
            current_dir / "SuperGlue", 
            current_dir
        ]
        
        for path in superglue_paths:
            hloc_file = path / "hloc_pipeline.py"
            if hloc_file.exists():
                # í•´ë‹¹ ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
                sys.path.insert(0, str(path))
                
                # ëª¨ë“ˆ import
                from hloc_pipeline import readHlocSceneInfo
                print(f"âœ“ Hloc pipeline imported from {path}")
                return readHlocSceneInfo
        
        print("âœ— Hloc pipeline not found")
        return None
        
    except ImportError as e:
        print(f"âœ— Hloc import failed: {e}")
        return None

# Hloc íŒŒì´í”„ë¼ì¸ import ì‹œë„
readHlocSceneInfo = import_hloc_pipeline()
HLOC_PIPELINE_AVAILABLE = (readHlocSceneInfo is not None)


def readSuperGlueSceneInfo(path, images="images", eval=False, train_test_exp=False, 
                          llffhold=8, superglue_config="outdoor", max_images=100):
    """SuperGlue ì™„ì „ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ SceneInfo ìƒì„±"""
    
    print("\n" + "="*60)
    print("           SUPERGLUE + 3DGS PIPELINE")
    print("="*60)
    
    print(f"ğŸ“ Source path: {path}")
    print(f"ğŸ–¼ï¸  Images folder: {images}")
    print(f"ğŸ”§ SuperGlue config: {superglue_config}")
    print(f"ğŸ“Š Max images: {max_images}")
    print(f"ğŸš€ Pipeline available: {SUPERGLUE_PIPELINE_AVAILABLE}")
    
    # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    images_folder = Path(path) / images
    if not images_folder.exists():
        # fallback ê²½ë¡œë“¤ ì‹œë„
        fallback_paths = [Path(path), Path(path) / "input"]
        for fallback in fallback_paths:
            if fallback.exists():
                images_folder = fallback
                break
    
    print(f"ğŸ“‚ Using images folder: {images_folder}")
    
    if SUPERGLUE_PIPELINE_AVAILABLE:
        try:
            print("\nğŸ”¥ STARTING SUPERGLUE PIPELINE...")
            
            # SuperGlue ì„¤ì •
            config = {
                'superpoint': {
                    'nms_radius': 3,
                    'keypoint_threshold': 0.003,
                    'max_keypoints': 4096
                },
                'superglue': {
                    'weights': superglue_config,
                    'sinkhorn_iterations': 30,
                    'match_threshold': 0.15,
                }
            }
            
            # ì¶œë ¥ ë””ë ‰í† ë¦¬
            output_folder = Path(path) / "superglue_sfm_output"
            
            # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            pipeline = SuperGlue3DGSPipeline(config)
            
            print(f"ğŸ¯ Calling process_images_to_3dgs...")
            print(f"   - Input: {images_folder}")
            print(f"   - Output: {output_folder}")
            print(f"   - Max images: {max_images}")
            
            scene_info = pipeline.process_images_to_3dgs(
                image_dir=str(images_folder),
                output_dir=str(output_folder),
                max_images=max_images
            )
            
            print("\nğŸ‰ SUPERGLUE PIPELINE SUCCESS!")
            print(f"âœ“ Training cameras: {len(scene_info.train_cameras)}")
            print(f"âœ“ Test cameras: {len(scene_info.test_cameras)}")
            print(f"âœ“ Point cloud: {len(scene_info.point_cloud.points)} points")
            print(f"âœ“ Scene radius: {scene_info.nerf_normalization['radius']:.3f}")
            
            return scene_info
            
        except Exception as e:
            print(f"\nâŒ SUPERGLUE PIPELINE FAILED: {e}")
            import traceback
            traceback.print_exc()
            print("\nâš ï¸  Falling back to simple camera arrangement...")
            
    else:
        print("\nâš ï¸  SuperGlue pipeline not available, using fallback...")
    
    # Fallback: ê°„ë‹¨í•œ ì¹´ë©”ë¼ ë°°ì¹˜
    return _create_fallback_scene_info(images_folder, max_images)

def readSuperGlueCOLMAPHybridSceneInfo(path, images="images", eval=False, train_test_exp=False, 
                                      llffhold=8, superglue_config="outdoor", max_images=100, colmap_exe="colmap"):
    """SuperGlue + COLMAP í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ SceneInfo ìƒì„±"""
    
    print("\n" + "="*60)
    print("    SUPERGLUE + COLMAP HYBRID PIPELINE")
    print("="*60)
    
    print(f"ğŸ“ Source path: {path}")
    print(f"ğŸ–¼ï¸  Images folder: {images}")
    print(f"ğŸ”§ SuperGlue config: {superglue_config}")
    print(f"ğŸ“Š Max images: {max_images}")
    print(f"ğŸ”§ COLMAP exe: {colmap_exe}")
    print(f"ğŸš€ Hybrid pipeline available: {SUPERGLUE_COLMAP_HYBRID_AVAILABLE}")
    
    # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    images_folder = Path(path) / images
    if not images_folder.exists():
        # fallback ê²½ë¡œë“¤ ì‹œë„
        fallback_paths = [Path(path), Path(path) / "input"]
        for fallback in fallback_paths:
            if fallback.exists():
                images_folder = fallback
                break
    
    print(f"ğŸ“‚ Using images folder: {images_folder}")
    
    if SUPERGLUE_COLMAP_HYBRID_AVAILABLE:
        try:
            print("\nğŸ”¥ STARTING SUPERGLUE + COLMAP HYBRID PIPELINE...")
            
            # ì¶œë ¥ ë””ë ‰í† ë¦¬
            output_folder = Path(path) / "superglue_colmap_hybrid_output"
            
            # í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            pipeline = SuperGlueCOLMAPHybrid(
                colmap_exe=colmap_exe,
                device="cuda" if torch.cuda.is_available() else "cpu"
            )
            
            print(f"ğŸ¯ Calling process_images...")
            print(f"   - Input: {images_folder}")
            print(f"   - Output: {output_folder}")
            print(f"   - Max images: {max_images}")
            
            scene_info = pipeline.process_images(
                image_dir=str(images_folder),
                output_dir=str(output_folder),
                max_images=max_images
            )
            
            if scene_info:
                print("\nğŸ‰ SUPERGLUE + COLMAP HYBRID PIPELINE SUCCESS!")
                print(f"âœ“ Training cameras: {len(scene_info.train_cameras)}")
                print(f"âœ“ Test cameras: {len(scene_info.test_cameras)}")
                print(f"âœ“ Point cloud: {len(scene_info.point_cloud.points)} points")
                print(f"âœ“ Scene radius: {scene_info.nerf_normalization['radius']:.3f}")
                
                return scene_info
            else:
                print("\nâŒ Hybrid pipeline returned None")
                raise RuntimeError("Hybrid pipeline failed to create scene_info")
                
        except Exception as e:
            print(f"\nâŒ SUPERGLUE + COLMAP HYBRID PIPELINE FAILED: {e}")
            import traceback
            traceback.print_exc()
            print("\nâš ï¸  Falling back to simple camera arrangement...")
            
    else:
        print("\nâš ï¸  SuperGlue + COLMAP hybrid pipeline not available, using fallback...")
    
    # Fallback: ê°„ë‹¨í•œ ì¹´ë©”ë¼ ë°°ì¹˜
    return _create_fallback_scene_info(images_folder, max_images)

def _create_fallback_scene_info(images_folder, max_images):
    """SuperGlue ì‹¤íŒ¨ì‹œ fallback scene ìƒì„±"""
    
    print(f"\nğŸ“‹ Creating fallback scene from {images_folder}")
    
    # ì´ë¯¸ì§€ ìˆ˜ì§‘
    image_paths = []
    extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']
    
    for ext in extensions:
        image_paths.extend(list(Path(images_folder).glob(ext)))
    
    image_paths.sort()
    image_paths = image_paths[:max_images]
    
    if len(image_paths) == 0:
        raise ValueError(f"No images found in {images_folder}")
    
    print(f"ğŸ“¸ Found {len(image_paths)} images")
    
    # CameraInfo ìƒì„±
    cam_infos = []
    for i, image_path in enumerate(image_paths):
        # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
        try:
            with Image.open(image_path) as img:
                width, height = img.size
        except:
            width, height = 640, 480
        
        # ì›í˜• ë°°ì¹˜ (ë” realisticí•œ ì¹´ë©”ë¼ ë°°ì¹˜)
        angle = i * (2 * np.pi / len(image_paths))
        radius = 3.0
        
        # ì¹´ë©”ë¼ê°€ ì›ì ì„ ë°”ë¼ë³´ë„ë¡ ì„¤ì •
        cam_pos = np.array([
            radius * np.cos(angle),
            0.0,  # YëŠ” ê³ ì •
            radius * np.sin(angle)
        ], dtype=np.float32)
        
        # ì›ì ì„ ë°”ë¼ë³´ëŠ” íšŒì „ í–‰ë ¬
        forward = -cam_pos / np.linalg.norm(cam_pos)  # ì›ì ì„ í–¥í•¨
        right = np.cross(forward, np.array([0, 1, 0]))
        right = right / np.linalg.norm(right)
        up = np.cross(right, forward)
        
        R = np.column_stack([right, up, forward]).astype(np.float32)
        T = cam_pos
        
        # FOV ì„¤ì •
        focal_length = max(width, height) * 0.8
        FovX = focal2fov(focal_length, width)
        FovY = focal2fov(focal_length, height)
        
        cam_info = CameraInfo(
            uid=i,
            R=R,
            T=T,
            FovY=float(FovY),
            FovX=float(FovX),
            image_path=str(image_path),
            image_name=image_path.name,
            width=width,
            height=height,
            depth_params=None,
            depth_path="",
            is_test=(i % 8 == 0)  # 8ì¥ë§ˆë‹¤ í…ŒìŠ¤íŠ¸ìš©
        )
        cam_infos.append(cam_info)
    
    # í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„± (ì›ì  ì£¼ë³€ì— êµ¬í˜• ë¶„í¬)
    n_points = 5000
    
    # êµ¬í˜• ë¶„í¬
    phi = np.random.uniform(0, 2*np.pi, n_points)
    costheta = np.random.uniform(-1, 1, n_points)
    u = np.random.uniform(0, 1, n_points)
    
    theta = np.arccos(costheta)
    r = 1.5 * np.cbrt(u)  # êµ¬í˜• ë¶„í¬ë¥¼ ìœ„í•œ ë°˜ì§€ë¦„
    
    x = r * np.sin(theta) * np.cos(phi)
    y = r * np.sin(theta) * np.sin(phi) 
    z = r * np.cos(theta)
    
    points = np.column_stack([x, y, z]).astype(np.float32)
    
    # ì»¬ëŸ¬ëŠ” ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
    colors = np.abs(points).astype(np.float32)
    colors = colors / np.max(colors)  # ì •ê·œí™”
    
    # ë²•ì„ ë²¡í„° (ì™¸í–¥)
    normals = points / np.linalg.norm(points, axis=1, keepdims=True)
    
    pcd = BasicPointCloud(points=points, colors=colors, normals=normals)
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
    train_cams = [c for c in cam_infos if not c.is_test]
    test_cams = [c for c in cam_infos if c.is_test]
    
    # NeRF ì •ê·œí™”
    cam_centers = []
    for cam in cam_infos:
        W2C = getWorld2View2(cam.R, cam.T)
        C2W = np.linalg.inv(W2C)
        cam_centers.append(C2W[:3, 3])
    
    if cam_centers:
        cam_centers = np.array(cam_centers)
        center = np.mean(cam_centers, axis=0)
        distances = np.linalg.norm(cam_centers - center, axis=1)
        radius = np.max(distances) * 1.1
    else:
        center = np.zeros(3)
        radius = 3.0
    
    nerf_norm = {"translate": -center, "radius": radius}
    
    scene_info = SceneInfo(
        point_cloud=pcd,
        train_cameras=train_cams,
        test_cameras=test_cams,
        nerf_normalization=nerf_norm,
        ply_path="",
        is_nerf_synthetic=False
    )
    
    print(f"âœ“ Fallback scene created:")
    print(f"  - {len(train_cams)} training cameras")
    print(f"  - {len(test_cams)} test cameras") 
    print(f"  - {len(points)} 3D points")
    print(f"  - Scene radius: {radius:.2f}")
    
    return scene_info


class SimpleSuperGluePipeline:
    """ê°„ì†Œí™”ëœ SuperGlue 3DGS íŒŒì´í”„ë¼ì¸ (fallback í¬í•¨)"""
    
    def __init__(self, config=None, device='cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        
        if SUPERGLUE_AVAILABLE and Matching is not None:
            # SuperGlue ì„¤ì •
            if config is None:
                config = {
                    'superpoint': {
                        'nms_radius': 4,
                        'keypoint_threshold': 0.005,
                        'max_keypoints': 1024
                    },
                    'superglue': {
                        'weights': 'outdoor',
                        'sinkhorn_iterations': 20,
                        'match_threshold': 0.2,
                    }
                }
            
            try:
                self.matching = Matching(config).eval().to(self.device)
                self.superglue_ready = True
                print(f"SuperGlue initialized on {self.device}")
            except Exception as e:
                print(f"SuperGlue initialization failed: {e}")
                self.superglue_ready = False
        else:
            self.superglue_ready = False
            print("SuperGlue not available, using simple pose estimation")
        
        # SfM ë°ì´í„°
        self.cameras = {}
        self.points_3d = {}
        self.image_features = {}
    
    def process_images_to_scene_info(self, image_dir, max_images=100):
        """ì´ë¯¸ì§€ë¥¼ SceneInfoë¡œ ë³€í™˜"""
        
        print(f"\n=== Processing {max_images} images with SuperGlue Pipeline ===")
        
        # 1. ì´ë¯¸ì§€ ìˆ˜ì§‘
        image_paths = self._collect_images(image_dir, max_images)
        print(f"Found {len(image_paths)} images")
        
        if len(image_paths) == 0:
            raise ValueError(f"No images found in {image_dir}")
        
        if self.superglue_ready:
            # 2. SuperGlue íŒŒì´í”„ë¼ì¸
            try:
                return self._superglue_pipeline(image_paths)
            except Exception as e:
                print(f"SuperGlue pipeline failed: {e}")
                print("Falling back to simple arrangement...")
                return self._simple_arrangement(image_paths)
        else:
            # 3. ê°„ë‹¨í•œ ë°°ì¹˜
            return self._simple_arrangement(image_paths)
    
    def _collect_images(self, image_dir, max_images):
        """ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘"""
        image_dir = Path(image_dir)
        image_paths = []
        
        extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']
        for ext in extensions:
            image_paths.extend(list(image_dir.glob(ext)))
        
        image_paths.sort()
        return image_paths[:max_images]
    
    def debug_superpoint_output(self, image_path):
        image = self._load_image(image_path)
        inp = frame2tensor(image, self.device)
    
        with torch.no_grad():
            pred = self.matching.superpoint({'image': inp})
    
        print(f"SuperPoint output keys: {pred.keys()}")
        for key, value in pred.items():
            if isinstance(value, torch.Tensor):
                print(f"  {key}: shape={value.shape}, dtype={value.dtype}")
            else:
                print(f"  {key}: {type(value)}")
    
        return pred
    
    def _superglue_pipeline(self, image_paths):
        """SuperGlue ê¸°ë°˜ SfM íŒŒì´í”„ë¼ì¸"""
        
        print("Running SuperGlue SfM pipeline...")
        
        # 1. íŠ¹ì§•ì  ì¶”ì¶œ
        print("1. Extracting features...")
        self._extract_features(image_paths[:20])  # ì²˜ìŒ 20ì¥ë§Œ ì²˜ë¦¬
        
        # 2. ë§¤ì¹­
        print("2. Matching features...")
        matches = self._match_sequential()
        
        # 3. í¬ì¦ˆ ì¶”ì •
        print("3. Estimating poses...")
        self._estimate_poses_simple(matches)
        
        # 4. SceneInfo ìƒì„±
        print("4. Creating scene info...")
        return self._create_scene_info(image_paths[:len(self.cameras)])
    
    def visualize_matches(self, i, j, save_path=None):
        """ë§¤ì¹­ ê²°ê³¼ ì‹œê°í™”"""
        if (i, j) not in self.matches:
            print(f"No matches found between images {i} and {j}")
            return
    
        # ì´ë¯¸ì§€ ë¡œë“œ
        img0 = cv2.imread(self.image_features[i]['image_path'])
        img1 = cv2.imread(self.image_features[j]['image_path'])
    
        # ë§¤ì¹­ í¬ì¸íŠ¸ ì¶”ì¶œ
        matches = self.matches[(i, j)]
        kpts0 = self.image_features[i]['keypoints']
        kpts1 = self.image_features[j]['keypoints']
    
        # ë§¤ì¹­ ì‹œê°í™”
        matched_img = cv2.drawMatches(
            img0, [cv2.KeyPoint(kpts0[m[0]][0], kpts0[m[0]][1], 1) for m in matches],
            img1, [cv2.KeyPoint(kpts1[m[1]][0], kpts1[m[1]][1], 1) for m in matches],
            [cv2.DMatch(idx, idx, 0) for idx in range(len(matches))],
            None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS
        )
    
        if save_path:
            cv2.imwrite(save_path, matched_img)
    
        return matched_img
    
    def _extract_features(self, image_paths):
        """SuperPointë¡œ íŠ¹ì§•ì  ì¶”ì¶œ"""
        for i, image_path in enumerate(image_paths):
            print(f"  {i+1}/{len(image_paths)}: {image_path.name}")
            
            self.debug_superpoint_output(image_path)
            
            image = self._load_image(image_path)
            if image is None:
                continue
            
            # SuperPoint íŠ¹ì§•ì  ì¶”ì¶œ
            inp = frame2tensor(image, self.device)
            with torch.no_grad():
                pred = self.matching.superpoint({'image': inp})
            
            self.image_features[i] = {
                'keypoints': pred['keypoints'][0].cpu().numpy(),
                'descriptors': pred['descriptors'][0].cpu().numpy(),
                'scores': pred['scores'][0].cpu().numpy(),
                'image_path': str(image_path),
                'image_size': image.shape[:2]
            }
            
            if i > 1:
                # visualize image match
                self.visualize_matches(i-1, i, save_path="output/match_viz/")
        
    
    
    def _match_sequential(self):
        """ìˆœì°¨ì  ë§¤ì¹­"""
        matches = {}
        n_images = len(self.image_features)
        
        for i in range(n_images - 1):
            j = i + 1
            match_result = self._match_pair(i, j)
            if len(match_result) > 10:
                matches[(i, j)] = match_result
        
        print(f"  Found {len(matches)} good matches")
        return matches
    
    def _match_pair(self, i, j):
        """ë” ì•ˆì „í•œ ë§¤ì¹­ í•¨ìˆ˜"""
        try:
            feat0 = self.image_features[i]
            feat1 = self.image_features[j]
        
            # ì…ë ¥ ë°ì´í„° í™•ì¸
            if 'keypoints' not in feat0 or 'keypoints' not in feat1:
                return []
        
            # ë§¤ì¹­ ìˆ˜í–‰
            pred = self.matching({
                'keypoints0': torch.from_numpy(feat0['keypoints']).float().to(self.device),
                'keypoints1': torch.from_numpy(feat1['keypoints']).float().to(self.device),
                'descriptors0': torch.from_numpy(feat0['descriptors']).float().to(self.device),
                'descriptors1': torch.from_numpy(feat1['descriptors']).float().to(self.device),
                'scores0': torch.from_numpy(feat0['scores']).float().to(self.device),
                'scores1': torch.from_numpy(feat1['scores']).float().to(self.device),
                'image0': torch.zeros(1, 1, *feat0['image_size']).to(self.device),
                'image1': torch.zeros(1, 1, *feat1['image_size']).to(self.device),
            })
            
            self.visualize_matches(i, j, save_path="output/match_viz/")
        
            # ë§¤ì¹­ ê²°ê³¼ ì²˜ë¦¬
            matches = pred['matches0'][0].cpu().numpy()
            confidence = pred['matching_scores0'][0].cpu().numpy()
        
            # ìœ íš¨í•œ ë§¤ì¹­ë§Œ ì„ íƒ
            valid = matches > -1
            matches = matches[valid]
            confidence = confidence[valid]
        
            # ì‹ ë¢°ë„ ê¸°ì¤€ í•„í„°ë§
            conf_mask = confidence > 0.2
            matches = matches[conf_mask]
            confidence = confidence[conf_mask]
        
            return matches
        
        except Exception as e:
            print(f"  Matching failed for pair {i}-{j}: {e}")
            return []
    
    def _estimate_poses_simple(self, matches):
        """ê°„ë‹¨í•œ í¬ì¦ˆ ì¶”ì •"""
        # ì²« ë²ˆì§¸ ì¹´ë©”ë¼ë¥¼ ì›ì ìœ¼ë¡œ
        self.cameras[0] = {
            'R': np.eye(3, dtype=np.float32),
            'T': np.zeros(3, dtype=np.float32),
            'K': self._estimate_intrinsics(0)
        }
        
        # ìˆœì°¨ì  í¬ì¦ˆ ì¶”ì •
        for cam_id in range(1, len(self.image_features)):
            if (cam_id-1, cam_id) in matches:
                R, T = self._estimate_relative_pose(cam_id-1, cam_id, matches[(cam_id-1, cam_id)])
                if R is not None:
                    self.cameras[cam_id] = {
                        'R': R,
                        'T': T,
                        'K': self._estimate_intrinsics(cam_id)
                    }
                    continue
            
            # ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ë°°ì¹˜
            angle = cam_id * 0.3
            self.cameras[cam_id] = {
                'R': np.array([[np.cos(angle), 0, np.sin(angle)],
                               [0, 1, 0],
                               [-np.sin(angle), 0, np.cos(angle)]], dtype=np.float32),
                'T': np.array([3*np.sin(angle), 0, 3*(1-np.cos(angle))], dtype=np.float32),
                'K': self._estimate_intrinsics(cam_id)
            }
    
    def _estimate_relative_pose(self, cam_i, cam_j, match_list):
        """Essential Matrixë¡œ ìƒëŒ€ í¬ì¦ˆ ì¶”ì •"""
        if len(match_list) < 8:
            return None, None
        
        kpts_i = self.image_features[cam_i]['keypoints']
        kpts_j = self.image_features[cam_j]['keypoints']
        
        pts_i = np.array([kpts_i[idx_i] for idx_i, _, conf in match_list if conf > 0.4])
        pts_j = np.array([kpts_j[idx_j] for _, idx_j, conf in match_list if conf > 0.4])
        
        if len(pts_i) < 8:
            return None, None
        
        K_i = self.cameras[cam_i]['K']
        K_j = self._estimate_intrinsics(cam_j)
        
        try:
            E, mask = cv2.findEssentialMat(pts_i, pts_j, K_i, 
                                           method=cv2.RANSAC, 
                                           prob=0.999, threshold=1.0)
            
            if E is not None:
                _, R, T, _ = cv2.recoverPose(E, pts_i, pts_j, K_i)
                return R, T.flatten()
        except:
            pass
        
        return None, None
    
    def _estimate_intrinsics(self, cam_id):
        """ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ì¶”ì •"""
        h, w = self.image_features[cam_id]['image_size']
        focal = max(w, h) * 0.8
        
        return np.array([
            [focal, 0, w/2],
            [0, focal, h/2],
            [0, 0, 1]
        ], dtype=np.float32)
    
    def _simple_arrangement(self, image_paths):
        """ê°„ë‹¨í•œ ì›í˜• ì¹´ë©”ë¼ ë°°ì¹˜"""
        print("Using simple circular camera arrangement...")
        
        cam_infos = []
        for i, image_path in enumerate(image_paths):
            # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
            try:
                with Image.open(image_path) as img:
                    width, height = img.size
            except:
                width, height = 1920, 1080
            
            # ì›í˜• ë°°ì¹˜
            angle = (i / len(image_paths)) * 2 * np.pi
            radius = 4.0
            
            R = np.array([
                [np.cos(angle), 0, np.sin(angle)],
                [0, 1, 0],
                [-np.sin(angle), 0, np.cos(angle)]
            ], dtype=np.float32)
            
            T = np.array([
                radius * np.sin(angle),
                0,
                radius * (1 - np.cos(angle))
            ], dtype=np.float32)
            
            # FOV ê³„ì‚°
            focal = max(width, height) * 0.8
            FovX = 2 * np.arctan(width / (2 * focal))
            FovY = 2 * np.arctan(height / (2 * focal))
            
            cam_info = CameraInfo(
                uid=i,
                R=R,
                T=T,
                FovY=float(FovY),
                FovX=float(FovX),
                image_path=str(image_path),
                image_name=image_path.name,
                width=width,
                height=height,
                depth_params=None,
                depth_path="",
                is_test=(i % 8 == 0)
            )
            cam_infos.append(cam_info)
        
        # ê¸°ë³¸ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ
        n_points = 10000
        points = np.random.randn(n_points, 3).astype(np.float32) * 2
        colors = np.random.rand(n_points, 3).astype(np.float32)
        normals = np.random.randn(n_points, 3).astype(np.float32)
        normals = normals / np.linalg.norm(normals, axis=1, keepdims=True)
        
        pcd = BasicPointCloud(points=points, colors=colors, normals=normals)
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        train_cams = [c for c in cam_infos if not c.is_test]
        test_cams = [c for c in cam_infos if c.is_test]
        
        # NeRF ì •ê·œí™”
        nerf_norm = self._compute_nerf_normalization(train_cams)
        
        return SceneInfo(
            point_cloud=pcd,
            train_cameras=train_cams,
            test_cameras=test_cams,
            nerf_normalization=nerf_norm,
            ply_path="",
            is_nerf_synthetic=False
        )
    
    def _create_scene_info(self, image_paths):
        """SuperGlue ê²°ê³¼ë¡œ SceneInfo ìƒì„±"""
        
        cam_infos = []
        for cam_id in sorted(self.cameras.keys()):
            cam = self.cameras[cam_id]
            image_path = self.image_features[cam_id]['image_path']
            h, w = self.image_features[cam_id]['image_size']
            
            # FoV ê³„ì‚°
            K = cam['K']
            focal_x, focal_y = K[0, 0], K[1, 1]
            FovX = 2 * np.arctan(w / (2 * focal_x))
            FovY = 2 * np.arctan(h / (2 * focal_y))
            
            cam_info = CameraInfo(
                uid=cam_id,
                R=cam['R'],
                T=cam['T'],
                FovY=float(FovY),
                FovX=float(FovX),
                image_path=image_path,
                image_name=Path(image_path).name,
                width=w,
                height=h,
                depth_params=None,
                depth_path="",
                is_test=(cam_id % 8 == 0)
            )
            cam_infos.append(cam_info)
        
        # ê°„ë‹¨í•œ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ
        n_points = 5000
        points = np.random.randn(n_points, 3).astype(np.float32) * 1.5
        colors = np.random.rand(n_points, 3).astype(np.float32)
        normals = np.random.randn(n_points, 3).astype(np.float32)
        normals = normals / np.linalg.norm(normals, axis=1, keepdims=True)
        
        pcd = BasicPointCloud(points=points, colors=colors, normals=normals)
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        train_cams = [c for c in cam_infos if not c.is_test]
        test_cams = [c for c in cam_infos if c.is_test]
        
        # NeRF ì •ê·œí™”
        nerf_norm = self._compute_nerf_normalization(train_cams)
        
        return SceneInfo(
            point_cloud=pcd,
            train_cameras=train_cams,
            test_cameras=test_cams,
            nerf_normalization=nerf_norm,
            ply_path="",
            is_nerf_synthetic=False
        )
    
    def _compute_nerf_normalization(self, cam_infos):
        """NeRF ì •ê·œí™” íŒŒë¼ë¯¸í„° ê³„ì‚°"""
        cam_centers = []
        for cam in cam_infos:
            W2C = getWorld2View2(cam.R, cam.T)
            C2W = np.linalg.inv(W2C)
            cam_centers.append(C2W[:3, 3:4])
        
        if cam_centers:
            cam_centers = np.hstack(cam_centers)
            center = np.mean(cam_centers, axis=1, keepdims=True).flatten()
            distances = np.linalg.norm(cam_centers - center.reshape(-1, 1), axis=0)
            radius = np.max(distances) * 1.1
        else:
            center = np.zeros(3)
            radius = 5.0
        
        return {"translate": -center, "radius": radius}
    
    def _load_image(self, image_path, resize=(640, 480)):
        """ì´ë¯¸ì§€ ë¡œë“œ"""
        try:
            image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)
            if image is None:
                return None
            
            if resize:
                image = cv2.resize(image, resize)
            
            return image.astype(np.float32)
        except:
            return None




sceneLoadTypeCallbacks = {
    "SuperGlue": readSuperGlueSceneInfo,
    "SuperGlueCOLMAPHybrid": readSuperGlueCOLMAPHybridSceneInfo,
    "Hloc": readHlocSceneInfo,
}

# sceneLoadTypeCallbacksì— ì¶”ê°€
sceneLoadTypeCallbacks["SuperGlue"] = readSuperGlueSceneInfo
sceneLoadTypeCallbacks["SuperGlueCOLMAPHybrid"] = readSuperGlueCOLMAPHybridSceneInfo

# Colmapê³¼ Blender ë¡œë”ë„ ì¶”ê°€ (ê¸°ì¡´ í•¨ìˆ˜ë“¤ì´ ìˆë‹¤ë©´)
try:
    from scene.colmap_loader import readColmapSceneInfo
    sceneLoadTypeCallbacks["Colmap"] = readColmapSceneInfo
except ImportError:
    print("Warning: Colmap loader not available")

try:
    from scene.blender_loader import readBlenderSceneInfo
    sceneLoadTypeCallbacks["Blender"] = readBlenderSceneInfo
except ImportError:
    print("Warning: Blender loader not available")

def test_superglue_connection():
    """SuperGlue ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("Testing SuperGlue connection...")
    print(f"SuperGlue3DGSPipeline available: {SUPERGLUE_PIPELINE_AVAILABLE}")
    
    if SUPERGLUE_PIPELINE_AVAILABLE:
        try:
            config = {
                'superpoint': {'nms_radius': 4, 'keypoint_threshold': 0.005, 'max_keypoints': 1024},
                'superglue': {'weights': 'outdoor', 'sinkhorn_iterations': 20, 'match_threshold': 0.2}
            }
            pipeline = SuperGlue3DGSPipeline(config)
            print("âœ“ SuperGlue pipeline instantiated successfully!")
            return True
        except Exception as e:
            print(f"âœ— SuperGlue pipeline test failed: {e}")
            return False
    else:
        print("âœ— SuperGlue pipeline not available")
        return False

if __name__ == "__main__":
    test_superglue_connection()