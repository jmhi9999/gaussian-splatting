# superglue_3dgs_complete.py
# SuperGlueì™€ 3DGS ì™„ì „ í†µí•© íŒŒì´í”„ë¼ì¸

import glob
from tkinter import Image
import numpy as np
import cv2
import torch
from pathlib import Path
import json
from scipy.optimize import least_squares
import matplotlib.pyplot as plt
from collections import defaultdict
import os
import sys
from scipy.spatial.distance import cdist

# SuperGlue ê´€ë ¨ imports
from models.matching import Matching
from models.utils import frame2tensor

# 3DGS ê´€ë ¨ imports - lazy importë¡œ ë³€ê²½
def get_3dgs_imports():
    """3DGS ê´€ë ¨ ëª¨ë“ˆë“¤ì„ lazy import"""
    # gaussian-splatting ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
    gaussian_splatting_root = Path(__file__).parent.parent
    if str(gaussian_splatting_root) not in sys.path:
        sys.path.insert(0, str(gaussian_splatting_root))
    
    try:
        from scene.dataset_readers import CameraInfo, SceneInfo
        from utils.graphics_utils import BasicPointCloud
        return CameraInfo, SceneInfo, BasicPointCloud
    except ImportError as e:
        print(f"Warning: Could not import 3DGS modules: {e}")
        return None, None, None


class SuperGlue3DGSPipeline:
    """SuperGlue ê¸°ë°˜ ì™„ì „í•œ 3DGS SfM íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config=None, device='cuda'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        
        # SuperGlue ì„¤ì • (ë” ì™„í™”ëœ ì„¤ì •)
        if config is None:
            config = {
                'superpoint': {
                    'nms_radius': 2,  # 3 â†’ 2ë¡œ ë” ì™„í™”
                    'keypoint_threshold': 0.0005,  # 0.001 â†’ 0.0005ë¡œ ë” ì™„í™”
                    'max_keypoints': 10240  # 8192 â†’ 10240ë¡œ ì¦ê°€
                },
                'superglue': {
                    'weights': 'outdoor',
                    'sinkhorn_iterations': 10,  # 15 â†’ 10ìœ¼ë¡œ ì™„í™”
                    'match_threshold': 0.01,  # 0.05 â†’ 0.01ë¡œ ëŒ€í­ ì™„í™”
                }
            }
        
        self.matching = Matching(config).eval().to(self.device)
        
        # SfM ë°ì´í„° ì €ì¥ì†Œ
        self.cameras = {}  # camera_id -> {'R': R, 'T': T, 'K': K, 'image_path': path}
        self.points_3d = {}  # point_id -> {'xyz': xyz, 'color': rgb, 'observations': [(cam_id, kpt_idx)]}
        self.image_features = {}  # image_id -> SuperPoint features
        self.matches = {}  # (img_i, img_j) -> SuperGlue matches
        
        # Bundle Adjustmentë¥¼ ìœ„í•œ ì¶”ê°€ ë°ì´í„°
        self.camera_graph = defaultdict(list)  # ì¹´ë©”ë¼ ì—°ê²° ê·¸ë˜í”„
        self.point_observations = defaultdict(list)  # í¬ì¸íŠ¸ ê´€ì°° ë°ì´í„°
        
        print(f'SuperGlue 3DGS Pipeline initialized on {self.device}')
    
    def process_images_to_3dgs(self, image_dir, output_dir, max_images=120):
        """ì´ë¯¸ì§€ë“¤ì„ 3DGS í˜•ì‹ìœ¼ë¡œ ì²˜ë¦¬"""
        print(f"Processing images from {image_dir} to {output_dir}")
        
        # output_dir ì €ì¥ (COLMAP intrinsics ì½ê¸°ìš©)
        self.output_dir = output_dir
        
        # ì´ë¯¸ì§€ ìˆ˜ì§‘
        image_paths = self._collect_images(image_dir, max_images)
        if not image_paths:
            raise RuntimeError("No images found")
        
        print(f"Found {len(image_paths)} images")
        
        # íŠ¹ì§•ì  ì¶”ì¶œ
        self._extract_all_features(image_paths)
        
        # ë§¤ì¹­
        self._intelligent_matching()
        
        # ì¹´ë©”ë¼ í¬ì¦ˆ ì¶”ì •
        self._estimate_camera_poses_robust()
        
        # ì‚¼ê°ì¸¡ëŸ‰
        n_points = self._triangulate_all_points_robust()
        
        # Bundle Adjustment
        self._bundle_adjustment_robust()
        
        # 3DGS SceneInfo ìƒì„±
        scene_info = self._create_3dgs_scene_info(image_paths)
        
        # 3DGS í˜•ì‹ìœ¼ë¡œ ì €ì¥
        self._save_3dgs_format(scene_info, output_dir)
        
        return scene_info
    
    def _collect_images(self, image_dir, max_images):
        """ì´ë¯¸ì§€ ìˆ˜ì§‘ ë° ì •ë ¬"""
        image_dir = Path(image_dir)
        image_paths = []
        
        # ì§€ì›í•˜ëŠ” í™•ì¥ì
        extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']
        for ext in extensions:
            image_paths.extend(list(image_dir.glob(ext)))
        
        # ì •ë ¬ ë° ì œí•œ
        image_paths.sort()
        return image_paths[:max_images]
    
    def _extract_all_features(self, image_paths):
        """ëª¨ë“  ì´ë¯¸ì§€ì—ì„œ SuperPoint íŠ¹ì§•ì  ì¶”ì¶œ (ìˆ˜ì •ëœ ë²„ì „)"""
        for i, image_path in enumerate(image_paths):
            print(f"  {i+1:3d}/{len(image_paths)}: {image_path.name}")
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = self._load_image(image_path)
            if image is None:
                continue
            
            # SuperPoint íŠ¹ì§•ì  ì¶”ì¶œ
            inp = frame2tensor(image, self.device)
            with torch.no_grad():
                pred = self.matching.superpoint({'image': inp})
            
            # ê²°ê³¼ ì €ì¥ - ëª¨ë“  í•„ìš”í•œ í‚¤ í¬í•¨
            self.image_features[i] = {
                'keypoints': pred['keypoints'][0].cpu().numpy(),
                'descriptors': pred['descriptors'][0].cpu().numpy(), 
                'scores': pred['scores'][0].cpu().numpy(),
                'image_path': str(image_path),
                'image_size': image.shape[:2]  # (H, W)
            }
            
            print(f"    Keypoints: {self.image_features[i]['keypoints'].shape[0]}")
            
        print(f"  Extracted features from {len(self.image_features)} images")
    
    def _intelligent_matching(self, max_pairs=1500):
        """ì§€ëŠ¥ì  ì´ë¯¸ì§€ ë§¤ì¹­ (IMPROVED VERSION)"""
        n_images = len(self.image_features)
        
        # ì „ì—­ descriptors ê³„ì‚° (NEW)
        self._compute_global_descriptors()
        
        # 1. ìˆœì°¨ì  ë§¤ì¹­ - ëª¨ë“  ì´ë¯¸ì§€ë¥¼ í•œ ë°”í€´ ëŒê¸°
        sequential_count = 0
        for i in range(n_images):
            # ë‹¤ìŒ ì´ë¯¸ì§€ (ë§ˆì§€ë§‰ ì´ë¯¸ì§€ëŠ” ì²« ë²ˆì§¸ì™€ ì—°ê²°)
            next_i = (i + 1) % n_images
            
            matches = self._match_pair_superglue(i, next_i)
            if len(matches) > 8:  # 12 â†’ 8ë¡œ ì™„í™”
                self.matches[(i, next_i)] = matches
                self.camera_graph[i].append(next_i)
                self.camera_graph[next_i].append(i)
                sequential_count += 1
        
        print(f"    Sequential pairs: {sequential_count}")
        
        # 2. ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ (NEW)
        similarity_count = self._similarity_based_matching(max_pairs)
        print(f"    Similarity pairs: {similarity_count}")
        
        # 3. Loop closure ë§¤ì¹­ (NEW)
        loop_count = self._loop_closure_matching()
        print(f"    Loop closure pairs: {loop_count}")
        
        print(f"  Total matching pairs: {len(self.matches)}")

    def _compute_global_descriptors(self):
        """ì „ì—­ ì´ë¯¸ì§€ descriptor ê³„ì‚° (NEW METHOD)"""
        self.global_descriptors = {}
        
        for cam_id, features in self.image_features.items():
            descriptors = features['descriptors']  # (256, N)
            scores = features['scores']
            
            if len(scores) > 0:
                # Scoreë¡œ ê°€ì¤‘í‰ê· í•˜ì—¬ ì „ì—­ descriptor ê³„ì‚°
                weights = scores / (scores.sum() + 1e-10)
                global_desc = np.average(descriptors.T, weights=weights, axis=0)
                global_desc = global_desc / (np.linalg.norm(global_desc) + 1e-10)
                self.global_descriptors[cam_id] = global_desc
            else:
                self.global_descriptors[cam_id] = np.zeros(256)
                
    def _similarity_based_matching(self, max_pairs):
        """ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ (NEW METHOD)"""
        # ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
        n_images = len(self.global_descriptors)
        similarity_matrix = np.zeros((n_images, n_images))
        
        for i in range(n_images):
            for j in range(i+1, n_images):
                if i in self.global_descriptors and j in self.global_descriptors:
                    sim = np.dot(self.global_descriptors[i], self.global_descriptors[j])
                    similarity_matrix[i, j] = sim
                    similarity_matrix[j, i] = sim
        
        # ìœ ì‚¬í•œ ì´ë¯¸ì§€ë“¤ ë§¤ì¹­
        similarity_count = 0
        for cam_id in range(n_images):
            # ìœ ì‚¬ë„ ë†’ì€ ìƒìœ„ 12ê°œ ì„ íƒ (8 â†’ 12ë¡œ ì¦ê°€)
            similarities = similarity_matrix[cam_id]
            candidates = np.argsort(similarities)[::-1]
            candidates = [c for c in candidates if c != cam_id and similarities[c] > 0.2][:12]  # 0.3 â†’ 0.2, 8 â†’ 12
            
            for candidate in candidates:
                pair_key = (min(cam_id, candidate), max(cam_id, candidate))
                if pair_key in self.matches:
                    continue
                
                matches = self._match_pair_superglue(cam_id, candidate)
                if len(matches) > 10:  # 15 â†’ 10ìœ¼ë¡œ ì™„í™”
                    self.matches[pair_key] = matches
                    self.camera_graph[cam_id].append(candidate)
                    self.camera_graph[candidate].append(cam_id)
                    similarity_count += 1
                
                if len(self.matches) >= max_pairs:
                    return similarity_count
        
        return similarity_count

    def _loop_closure_matching(self):
        """Loop closure ë§¤ì¹­ (NEW METHOD)"""
        n_images = len(self.image_features)
        loop_count = 0
        
        # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ëª‡ ê°œ ì´ë¯¸ì§€ ê°„ ë§¤ì¹­
        for i in range(min(8, n_images//3)):  # 5 â†’ 8ë¡œ ì¦ê°€
            for j in range(max(n_images-8, 2*n_images//3), n_images):  # 5 â†’ 8ë¡œ ì¦ê°€
                if i >= j:
                    continue
                
                pair_key = (i, j)
                if pair_key in self.matches:
                    continue
                
                # ì „ì—­ ìœ ì‚¬ë„ ì²´í¬
                if hasattr(self, 'global_descriptors') and i in self.global_descriptors and j in self.global_descriptors:
                    sim = np.dot(self.global_descriptors[i], self.global_descriptors[j])
                    if sim > 0.3:  # 0.4 â†’ 0.3ìœ¼ë¡œ ì™„í™”
                        matches = self._match_pair_superglue(i, j)
                        if len(matches) > 15:  # 20 â†’ 15ë¡œ ì™„í™”
                            self.matches[pair_key] = matches
                            self.camera_graph[i].append(j)
                            self.camera_graph[j].append(i)
                            loop_count += 1
        
        return loop_count
    
    def _filter_low_quality_matches_very_relaxed(self):
        """ë§¤ìš° ì™„í™”ëœ ë‚®ì€ í’ˆì§ˆì˜ ë§¤ì¹­ í•„í„°ë§"""
        pairs_to_remove = []
        
        for (cam_i, cam_j), matches in self.matches.items():
            if len(matches) < 3:  # ë” ë‚®ì€ ì„ê³„ê°’ (5 â†’ 3)
                pairs_to_remove.append((cam_i, cam_j))
                continue
            
            # ë§¤ì¹­ í’ˆì§ˆ ë¶„ì„
            confidences = [conf for _, _, conf in matches]
            avg_confidence = np.mean(confidences)
            
            if avg_confidence < 0.1:  # ë” ë‚®ì€ ì„ê³„ê°’ (0.2 â†’ 0.1)
                pairs_to_remove.append((cam_i, cam_j))
                continue
            
            # ë§¤ì¹­ ë¶„í¬ ë¶„ì„ (ë” ì™„í™”ëœ ì¡°ê±´)
            if self._has_poor_matching_distribution_very_relaxed(cam_i, cam_j, matches):
                pairs_to_remove.append((cam_i, cam_j))
        
        # í•„í„°ë§ëœ ë§¤ì¹­ ì œê±°
        for pair in pairs_to_remove:
            cam_i, cam_j = pair
            del self.matches[pair]
            
            # ê·¸ë˜í”„ì—ì„œë„ ì œê±°
            if cam_j in self.camera_graph[cam_i]:
                self.camera_graph[cam_i].remove(cam_j)
            if cam_i in self.camera_graph[cam_j]:
                self.camera_graph[cam_j].remove(cam_i)
        
        print(f"  Filtered out {len(pairs_to_remove)} low-quality matches (very relaxed)")
    
    def _has_poor_matching_distribution_very_relaxed(self, cam_i, cam_j, matches):
        """ë§¤ìš° ì™„í™”ëœ ë§¤ì¹­ ë¶„í¬ ê²€ì‚¬"""
        kpts_i = self.image_features[cam_i]['keypoints']
        kpts_j = self.image_features[cam_j]['keypoints']
        
        # ì¸ë±ìŠ¤ ë²”ìœ„ ê²€ì¦
        valid_matches = []
        for idx_i, idx_j, conf in matches:
            if (idx_i < len(kpts_i) and idx_j < len(kpts_j) and 
                idx_i >= 0 and idx_j >= 0):
                valid_matches.append((idx_i, idx_j, conf))
        
        if len(valid_matches) < 2:  # ë” ë‚®ì€ ì„ê³„ê°’ (3 â†’ 2)
            return True
        
        # ë§¤ì¹­ëœ ì ë“¤ì˜ ìœ„ì¹˜ ë¶„ì„
        matched_i = np.array([kpts_i[idx_i] for idx_i, _, _ in valid_matches])
        matched_j = np.array([kpts_j[idx_j] for _, idx_j, _ in valid_matches])
        
        # ì´ë¯¸ì§€ í¬ê¸°
        h_i, w_i = self.image_features[cam_i]['image_size']
        h_j, w_j = self.image_features[cam_j]['image_size']
        
        # ê²½ê³„ ê·¼ì²˜ì˜ ë§¤ì¹­ì´ ë„ˆë¬´ ë§ì€ì§€ í™•ì¸ (ë” ì™„í™”ëœ ì¡°ê±´)
        border_threshold = 20  # ë” ì‘ì€ ê²½ê³„ (30 â†’ 20)
        
        border_matches_i = np.sum((matched_i[:, 0] < border_threshold) | 
                                  (matched_i[:, 0] > w_i - border_threshold) |
                                  (matched_i[:, 1] < border_threshold) | 
                                  (matched_i[:, 1] > h_i - border_threshold))
        
        border_matches_j = np.sum((matched_j[:, 0] < border_threshold) | 
                                  (matched_j[:, 0] > w_j - border_threshold) |
                                  (matched_j[:, 1] < border_threshold) | 
                                  (matched_j[:, 1] > h_j - border_threshold))
        
        # ê²½ê³„ ë§¤ì¹­ì´ ì „ì²´ì˜ 95% ì´ìƒì´ë©´ ë‚˜ìœ ë¶„í¬ (90% â†’ 95%)
        if border_matches_i > len(valid_matches) * 0.95 or border_matches_j > len(valid_matches) * 0.95:
            return True
        
        return False
    
    def _match_pair_superglue(self, cam_i, cam_j):
        """SuperGlue í˜ì–´ ë§¤ì¹­ (IMPROVED VERSION)"""
        try:
            feat_i = self.image_features[cam_i]
            feat_j = self.image_features[cam_j]
            
            # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
            data = {
                'image0': torch.zeros((1, 1, 480, 640)).to(self.device),
                'image1': torch.zeros((1, 1, 480, 640)).to(self.device),
                'keypoints0': torch.from_numpy(feat_i['keypoints']).unsqueeze(0).to(self.device),
                'keypoints1': torch.from_numpy(feat_j['keypoints']).unsqueeze(0).to(self.device),
                'descriptors0': torch.from_numpy(feat_i['descriptors']).unsqueeze(0).to(self.device),
                'descriptors1': torch.from_numpy(feat_j['descriptors']).unsqueeze(0).to(self.device),
                'scores0': torch.from_numpy(feat_i['scores']).unsqueeze(0).to(self.device),
                'scores1': torch.from_numpy(feat_j['scores']).unsqueeze(0).to(self.device),
            }
            
            # SuperGlue ë§¤ì¹­
            with torch.no_grad():
                result = self.matching.superglue(data)
            
            # ê²°ê³¼ ì¶”ì¶œ
            indices0 = result['indices0'][0].cpu().numpy()
            indices1 = result['indices1'][0].cpu().numpy()
            mscores0 = result['matching_scores0'][0].cpu().numpy()
            
            # ê°œì„ ëœ ë§¤ì¹­ í•„í„°ë§
            valid_matches = []
            threshold = 0.001  # 0.01 â†’ 0.001ë¡œ ëŒ€í­ ì™„í™”
            
            for i, j in enumerate(indices0):
                if j >= 0 and mscores0[i] > threshold:
                    # ìƒí˜¸ ë§¤ì¹­ í™•ì¸
                    if j < len(indices1) and indices1[j] == i:
                        # ì¸ë±ìŠ¤ ë²”ìœ„ ê²€ì¦
                        if i < len(feat_i['keypoints']) and j < len(feat_j['keypoints']):
                            valid_matches.append((i, j, mscores0[i]))
            
            # ê¸°í•˜í•™ì  í•„í„°ë§ ì¶”ê°€ (NEW)
            if len(valid_matches) >= 1:  # 3 â†’ 1ë¡œ ëŒ€í­ ì™„í™”
                valid_matches = self._geometric_filtering(valid_matches, feat_i['keypoints'], feat_j['keypoints'])
            
            return valid_matches
            
        except Exception as e:
            print(f"    SuperGlue matching failed for pair {cam_i}-{cam_j}: {e}")
            return []

    def _geometric_filtering(self, matches, kpts_i, kpts_j):
        """ê¸°í•˜í•™ì  í•„í„°ë§ (NEW METHOD)"""
        try:
            pts_i = np.array([kpts_i[m[0]] for m in matches])
            pts_j = np.array([kpts_j[m[1]] for m in matches])
            
            # í˜¸ëª¨ê·¸ë˜í”¼ ê¸°ë°˜ outlier ì œê±°
            H, mask = cv2.findHomography(pts_i, pts_j, cv2.RANSAC, 20.0)  # 10.0 â†’ 20.0ìœ¼ë¡œ ë” ì™„í™”
            
            if H is not None and mask is not None:
                inlier_matches = [matches[i] for i, is_inlier in enumerate(mask.flatten()) if is_inlier]
                if len(inlier_matches) >= 1:  # 4 â†’ 1ë¡œ ëŒ€í­ ì™„í™”
                    return inlier_matches
        except:
            pass
        
        return matches
    
    def _estimate_camera_poses_robust(self):
        """ê°œì„ ëœ ì¹´ë©”ë¼ í¬ì¦ˆ ì¶”ì • (ë” ì•ˆì „í•œ ë²„ì „)"""
        
        # ì²« ë²ˆì§¸ ì¹´ë©”ë¼ë¥¼ ì›ì ìœ¼ë¡œ ì„¤ì •
        self.cameras[0] = {
            'R': np.eye(3, dtype=np.float32),
            'T': np.zeros(3, dtype=np.float32),
            'K': self._estimate_intrinsics(0)
        }
        
        print(f"  Camera 0: Origin (reference)")
        
        # 1ë‹¨ê³„: ì—°ê²°ëœ ì¹´ë©”ë¼ë“¤ë§Œ í¬ì¦ˆ ì¶”ì •
        estimated_cameras = {0}
        queue = [0]
        
        while queue:
            current_cam = queue.pop(0)
            
            # í˜„ì¬ ì¹´ë©”ë¼ì™€ ì—°ê²°ëœ ì¹´ë©”ë¼ë“¤ í™•ì¸
            for neighbor_cam in self.camera_graph[current_cam]:
                if neighbor_cam in estimated_cameras:
                    continue
                
                # ë§¤ì¹­ ë°ì´í„° ì°¾ê¸°
                pair_key = (current_cam, neighbor_cam) if current_cam < neighbor_cam else (neighbor_cam, current_cam)
                if pair_key not in self.matches:
                    continue
                
                # Essential Matrix ê¸°ë°˜ í¬ì¦ˆ ì¶”ì •
                R_rel, T_rel = self._estimate_relative_pose_robust(current_cam, neighbor_cam, pair_key)
                
                if R_rel is not None and T_rel is not None:
                    # ì›”ë“œ ì¢Œí‘œê³„ì—ì„œì˜ ì ˆëŒ€ í¬ì¦ˆ ê³„ì‚°
                    R_ref, T_ref = self.cameras[current_cam]['R'], self.cameras[current_cam]['T']
                    
                    # ìƒëŒ€ í¬ì¦ˆë¥¼ ì ˆëŒ€ í¬ì¦ˆë¡œ ë³€í™˜
                    R_world = R_rel @ R_ref
                    T_world = R_rel @ T_ref + T_rel
                    
                    # í¬ì¦ˆ ìœ íš¨ì„± ê²€ì‚¬
                    if self._is_valid_rotation_matrix(R_world):
                        self.cameras[neighbor_cam] = {
                            'R': R_world.astype(np.float32),
                            'T': T_world.astype(np.float32),
                            'K': self._estimate_intrinsics(neighbor_cam)
                        }
                        
                        print(f"  Camera {neighbor_cam}: Estimated from camera {current_cam}")
                        estimated_cameras.add(neighbor_cam)
                        queue.append(neighbor_cam)
                    else:
                        print(f"  Camera {neighbor_cam}: Invalid pose, skipping...")
                else:
                    print(f"  Camera {neighbor_cam}: Pose estimation failed, will use default pose")
        
        # 2ë‹¨ê³„: ì—°ê²°ë˜ì§€ ì•Šì€ ì¹´ë©”ë¼ë“¤ì— ëŒ€í•œ ê¸°ë³¸ í¬ì¦ˆ ì„¤ì •
        for cam_id in range(len(self.image_features)):
            if cam_id not in estimated_cameras:
                print(f"  Camera {cam_id}: Using default pose (not connected)")
                # ê¸°ë³¸ ì›í˜• ë°°ì¹˜
                angle = cam_id * (2 * np.pi / len(self.image_features))
                radius = 3.0
                
                self.cameras[cam_id] = {
                    'R': np.array([[np.cos(angle), 0, np.sin(angle)],
                                   [0, 1, 0],
                                   [-np.sin(angle), 0, np.cos(angle)]], dtype=np.float32),
                    'T': np.array([radius * np.sin(angle), 0, radius * (1 - np.cos(angle))], dtype=np.float32),
                    'K': self._estimate_intrinsics(cam_id)
                }
        
        print(f"  Estimated poses for {len(estimated_cameras)} cameras")
        print(f"  Total cameras with poses: {len(self.cameras)}")
    
    def _estimate_relative_pose_robust(self, cam_i, cam_j, pair_key):
        """ê°œì„ ëœ ë‘ ì¹´ë©”ë¼ ê°„ ìƒëŒ€ í¬ì¦ˆ ì¶”ì • - ê¸°í•˜í•™ì  ê²€ì¦ ê°•í™”"""
        matches = self.matches[pair_key]
        
        if len(matches) < 8:  # ìµœì†Œ 8ê°œ ë§¤ì¹­ í•„ìš”
            print(f"    Pair {cam_i}-{cam_j}: Insufficient matches ({len(matches)} < 8)")
            return None, None
        
        # ë§¤ì¹­ì ë“¤ ì¶”ì¶œ
        kpts_i = self.image_features[cam_i]['keypoints']
        kpts_j = self.image_features[cam_j]['keypoints']
        
        print(f"    Pair {cam_i}-{cam_j}: kpts_i shape: {kpts_i.shape}, kpts_j shape: {kpts_j.shape}")
        
        # ğŸ”§ ê°œì„ ëœ ì‹ ë¢°ë„ ì„ê³„ê°’ (ë” í˜„ì‹¤ì ì¸ ê°’)
        high_conf_matches = [(idx_i, idx_j, conf) for idx_i, idx_j, conf in matches if conf > 0.1]  # 0.001 â†’ 0.1ë¡œ ê°œì„ 
        
        if len(high_conf_matches) < 8:  # ìµœì†Œ 8ê°œ í•„ìš”
            high_conf_matches = [(idx_i, idx_j, conf) for idx_i, idx_j, conf in matches if conf > 0.05]  # 0.0001 â†’ 0.05ë¡œ ê°œì„ 
        
        if len(high_conf_matches) < 8:
            print(f"    Pair {cam_i}-{cam_j}: Insufficient high-confidence matches ({len(high_conf_matches)} < 8)")
            return None, None
        
        # ğŸ”§ ì¸ë±ìŠ¤ ë²”ìœ„ ê²€ì¦ ê°•í™”
        valid_matches = []
        for idx_i, idx_j, conf in high_conf_matches:
            if (isinstance(idx_i, (int, np.integer)) and isinstance(idx_j, (int, np.integer)) and
                idx_i >= 0 and idx_j >= 0 and 
                idx_i < len(kpts_i) and idx_j < len(kpts_j)):
                valid_matches.append((idx_i, idx_j, conf))
        
        if len(valid_matches) < 8:
            print(f"    Pair {cam_i}-{cam_j}: Insufficient valid matches after index validation ({len(valid_matches)} < 8)")
            return None, None
        
        print(f"    Pair {cam_i}-{cam_j}: Using {len(valid_matches)} validated matches")
        
        # ğŸ”§ ê°œì„ ëœ í¬ì¸íŠ¸ ì¶”ì¶œ
        try:
            pts_i = np.array([kpts_i[idx_i] for idx_i, _, _ in valid_matches])
            pts_j = np.array([kpts_j[idx_j] for _, idx_j, _ in valid_matches])
        except IndexError as e:
            print(f"    IndexError during point extraction: {e}")
            return None, None
        
        # ğŸ”§ ê¸°í•˜í•™ì  ì¼ê´€ì„± ì‚¬ì „ ê²€ì¦
        if not self._check_geometric_consistency(pts_i, pts_j):
            print(f"    Pair {cam_i}-{cam_j}: Failed geometric consistency check")
            return None, None
        
        # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°
        K_i = self.cameras.get(cam_i, {}).get('K', self._estimate_intrinsics(cam_i))
        K_j = self._estimate_intrinsics(cam_j)
        
        # ğŸ”§ ê°œì„ ëœ Essential Matrix ì¶”ì • ë°©ë²•ë“¤
        methods = [
            (cv2.RANSAC, 0.5, 0.999),   # ë” ì—„ê²©í•œ ì„ê³„ê°’
            (cv2.LMEDS, 0.5, 0.99),
            (cv2.RANSAC, 1.0, 0.999),
            (cv2.RANSAC, 2.0, 0.99),
            (cv2.RANSAC, 3.0, 0.95)
        ]
        
        best_R, best_T = None, None
        best_inliers = 0
        best_quality = 0
        
        for method, threshold, confidence in methods:
            try:
                # Essential Matrix ì¶”ì •
                E, mask = cv2.findEssentialMat(
                    pts_i, pts_j, K_i,
                    method=method,
                    prob=confidence,
                    threshold=threshold,
                    maxIters=2000  # ë” ë§ì€ ë°˜ë³µ
                )
                
                if E is None or E.shape != (3, 3):
                    continue
                
                # í¬ì¦ˆ ë³µì›
                _, R, T, mask = cv2.recoverPose(E, pts_i, pts_j, K_i, mask=mask)
                
                if R is None or T is None:
                    continue
                
                inliers = np.sum(mask)
                
                if inliers >= 8:  # ìµœì†Œ 8ê°œ inlier í•„ìš”
                    # ğŸ”§ ê°œì„ ëœ í¬ì¦ˆ í’ˆì§ˆ ê²€ì¦
                    quality_score = self._evaluate_pose_quality(pts_i, pts_j, R, T.flatten(), K_i, K_j, mask)
                    
                    if quality_score > best_quality:
                        best_R, best_T = R, T.flatten()
                        best_inliers = inliers
                        best_quality = quality_score
                        
            except Exception as e:
                print(f"      Method {method} failed: {e}")
                continue
        
        if best_R is not None:
            print(f"    Pair {cam_i}-{cam_j}: Successfully estimated pose with {best_inliers} inliers, quality: {best_quality:.3f}")
        else:
            print(f"    Pair {cam_i}-{cam_j}: Failed to estimate pose")
        
        return best_R, best_T

    def _check_geometric_consistency(self, pts_i, pts_j):
        """ê¸°í•˜í•™ì  ì¼ê´€ì„± ì‚¬ì „ ê²€ì¦ (NEW METHOD)"""
        try:
            # 1. í˜¸ëª¨ê·¸ë˜í”¼ ê¸°ë°˜ ì¼ê´€ì„± ê²€ì‚¬
            H, mask = cv2.findHomography(pts_i, pts_j, cv2.RANSAC, 3.0)
            if H is not None:
                homography_inliers = np.sum(mask)
                if homography_inliers < len(pts_i) * 0.3:  # 30% ë¯¸ë§Œì´ë©´ ì‹¤íŒ¨
                    return False
            
            # 2. í¬ì¸íŠ¸ ë¶„í¬ ê²€ì‚¬ (ì´ë¯¸ì§€ í¬ê¸° ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ê°„ë‹¨í•œ ê²€ì‚¬ë§Œ)
            # í¬ì¸íŠ¸ë“¤ì´ ë„ˆë¬´ í•œ ê³³ì— ì§‘ì¤‘ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if len(pts_i) > 10:
                # í¬ì¸íŠ¸ë“¤ì˜ ë¶„ì‚° ê³„ì‚°
                var_i = np.var(pts_i, axis=0)
                var_j = np.var(pts_j, axis=0)
                
                # ë¶„ì‚°ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ë‚˜ìœ ë¶„í¬
                if np.min(var_i) < 100 or np.min(var_j) < 100:
                    return False
            
            # 3. í¬ì¸íŠ¸ ê°„ ê±°ë¦¬ ê²€ì‚¬
            # ë„ˆë¬´ ê°€ê¹Œìš´ í¬ì¸íŠ¸ë“¤ì´ ë§ì€ì§€ í™•ì¸
            distances_i = cdist(pts_i, pts_i)
            distances_j = cdist(pts_j, pts_j)
            
            # ëŒ€ê°ì„  ì œê±°
            np.fill_diagonal(distances_i, np.inf)
            np.fill_diagonal(distances_j, np.inf)
            
            min_dist_i = np.min(distances_i)
            min_dist_j = np.min(distances_j)
            
            # ìµœì†Œ ê±°ë¦¬ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ë‚˜ìœ ë¶„í¬
            if min_dist_i < 5 or min_dist_j < 5:
                return False
            
            return True
            
        except Exception as e:
            print(f"      Geometric consistency check failed: {e}")
            return True  # ì˜¤ë¥˜ì‹œ í†µê³¼

    def _evaluate_pose_quality(self, pts_i, pts_j, R, T, K_i, K_j, mask):
        """ê°œì„ ëœ í¬ì¦ˆ í’ˆì§ˆ í‰ê°€ (NEW METHOD)"""
        try:
            # 1. íšŒì „ í–‰ë ¬ ìœ íš¨ì„± í™•ì¸
            det = np.linalg.det(R)
            if abs(det - 1.0) > 0.1:
                return 0.0
            
            # 2. ì‚¼ê°ì¸¡ëŸ‰ í’ˆì§ˆ ê²€ì‚¬
            P_i = K_i @ np.hstack([np.eye(3), np.zeros((3, 1))])
            P_j = K_j @ np.hstack([R, T.reshape(-1, 1)])
            
            # inlier í¬ì¸íŠ¸ë“¤ë§Œ ì‚¬ìš©
            inlier_pts_i = pts_i[mask.flatten()]
            inlier_pts_j = pts_j[mask.flatten()]
            
            if len(inlier_pts_i) < 8:
                return 0.0
            
            # ì‚¼ê°ì¸¡ëŸ‰ í…ŒìŠ¤íŠ¸
            valid_points = 0
            total_error = 0.0
            
            for pt_i, pt_j in zip(inlier_pts_i, inlier_pts_j):
                try:
                    # ì‚¼ê°ì¸¡ëŸ‰
                    pt_4d = cv2.triangulatePoints(P_i, P_j, pt_i.reshape(2, 1), pt_j.reshape(2, 1))
                    
                    if abs(pt_4d[3, 0]) > 1e-10:
                        pt_3d = (pt_4d[:3] / pt_4d[3]).flatten()
                        
                        # ê±°ë¦¬ ì²´í¬
                        if 0.1 < np.linalg.norm(pt_3d) < 100:
                            # ì¬íˆ¬ì˜ ì˜¤ì°¨ ê³„ì‚°
                            proj_i = P_i @ np.append(pt_3d, 1)
                            proj_j = P_j @ np.append(pt_3d, 1)
                            
                            if proj_i[2] > 0 and proj_j[2] > 0:
                                proj_i_2d = proj_i[:2] / proj_i[2]
                                proj_j_2d = proj_j[:2] / proj_j[2]
                                
                                error_i = np.linalg.norm(proj_i_2d - pt_i)
                                error_j = np.linalg.norm(proj_j_2d - pt_j)
                                
                                total_error += max(error_i, error_j)
                                valid_points += 1
                                
                except:
                    continue
            
            if valid_points < 8:
                return 0.0
            
            # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            avg_error = total_error / valid_points
            inlier_ratio = len(inlier_pts_i) / len(pts_i)
            
            # ì˜¤ì°¨ê°€ ì‘ê³  inlier ë¹„ìœ¨ì´ ë†’ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
            quality_score = inlier_ratio * (1.0 / (1.0 + avg_error))
            
            return quality_score
            
        except Exception as e:
            print(f"      Pose quality evaluation failed: {e}")
            return 0.0
    
    def _estimate_pose_fallback(self, pts_i, pts_j, K_i, K_j):
        """OpenCV ì‹¤íŒ¨ì‹œ ì‚¬ìš©í•  fallback í¬ì¦ˆ ì¶”ì •"""
        try:
            # ê°„ë‹¨í•œ í˜¸ëª¨ê·¸ë˜í”¼ ê¸°ë°˜ ë°©ë²•
            H, mask = cv2.findHomography(pts_i, pts_j, cv2.RANSAC, 5.0)
            
            if H is None:
                return None, None
            
            # í˜¸ëª¨ê·¸ë˜í”¼ì—ì„œ íšŒì „ê³¼ ì´ë™ ì¶”ì¶œ (ê·¼ì‚¬)
            # ì´ëŠ” ì •í™•í•˜ì§€ ì•Šì§€ë§Œ ê¸°ë³¸ì ì¸ í¬ì¦ˆë¥¼ ì œê³µ
            K_inv = np.linalg.inv(K_i)
            R_approx = K_inv @ H @ K_i
            
            # SVDë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒì „ í–‰ë ¬ë¡œ ì •ê·œí™”
            U, _, Vt = np.linalg.svd(R_approx)
            R = U @ Vt
            
            # íšŒì „ í–‰ë ¬ ìœ íš¨ì„± ê²€ì‚¬
            if not self._is_valid_rotation_matrix(R):
                # ê¸°ë³¸ íšŒì „ í–‰ë ¬ ì‚¬ìš©
                R = np.eye(3)
            
            # ì´ë™ ë²¡í„° ì¶”ì • (ê°„ë‹¨í•œ ê·¼ì‚¬)
            T = np.array([0.1, 0.0, 0.0])  # ê¸°ë³¸ ì´ë™
            
            return R, T
            
        except Exception as e:
            print(f"      Fallback pose estimation failed: {e}")
            return None, None
    
    def _is_valid_rotation_matrix(self, R):
        """íšŒì „ í–‰ë ¬ì´ ìœ íš¨í•œì§€ í™•ì¸"""
        try:
            # í–‰ë ¬ì‹ì´ 1ì— ê°€ê¹Œìš´ì§€ í™•ì¸
            det = np.linalg.det(R)
            if abs(det - 1.0) > 0.1:
                return False
            
            # R * R^T = Iì¸ì§€ í™•ì¸
            I = np.eye(3)
            RRt = R @ R.T
            if np.max(np.abs(RRt - I)) > 0.1:
                return False
            
            return True
        except:
            return False
    
    def _verify_pose_quality_very_relaxed(self, pts_i, pts_j, R, T, K_i, K_j):
        """ë§¤ìš° ì™„í™”ëœ í¬ì¦ˆ í’ˆì§ˆ ê²€ì¦"""
        # ì¬íˆ¬ì˜ ì˜¤ì°¨ ê³„ì‚°
        P_i = K_i @ np.hstack([np.eye(3), np.zeros((3, 1))])
        P_j = K_j @ np.hstack([R, T.reshape(-1, 1)])
        
        errors = []
        depths_i = []
        depths_j = []
        
        for pt_i, pt_j in zip(pts_i, pts_j):
            # ì‚¼ê°ì¸¡ëŸ‰
            point_4d = cv2.triangulatePoints(P_i, P_j, pt_i.reshape(2, 1), pt_j.reshape(2, 1))
            if abs(point_4d[3, 0]) > 1e-10:
                point_3d = (point_4d[:3] / point_4d[3]).flatten()
                
                # ì¬íˆ¬ì˜ (3D ì¢Œí‘œê³„ì—ì„œ)
                proj_i_3d = P_i @ np.append(point_3d, 1)
                proj_j_3d = P_j @ np.append(point_3d, 1)
                
                # 2D ì¢Œí‘œë¡œ ë³€í™˜
                proj_i_2d = proj_i_3d[:2] / proj_i_3d[2]
                proj_j_2d = proj_j_3d[:2] / proj_j_3d[2]
                
                error_i = np.linalg.norm(proj_i_2d - pt_i)
                error_j = np.linalg.norm(proj_j_2d - pt_j)
                errors.append(max(error_i, error_j))
                
                # ê¹Šì´ ì •ë³´ ì €ì¥ (3D ì¢Œí‘œê³„ì—ì„œ)
                depths_i.append(proj_i_3d[2])
                depths_j.append(proj_j_3d[2])
        
        if len(errors) < 2:  # ë” ë‚®ì€ ì„ê³„ê°’ (3 â†’ 2)
            return False
        
        # ì˜¤ì°¨ í†µê³„
        median_error = np.median(errors)
        mean_error = np.mean(errors)
        max_error = np.max(errors)
        
        # ê¹Šì´ ê²€ì¦ (ë” ì™„í™”ëœ ì¡°ê±´)
        if depths_i and depths_j:
            depths_i = np.array(depths_i)
            depths_j = np.array(depths_j)
            
            # ê¹Šì´ê°€ ì–‘ìˆ˜ì¸ì§€ í™•ì¸
            if np.any(depths_i <= 0) or np.any(depths_j <= 0):
                return False
            
            # ê¹Šì´ ë¹„ìœ¨ì´ í•©ë¦¬ì ì¸ì§€ í™•ì¸ (ë” ì™„í™”ëœ ì¡°ê±´)
            depth_ratios = depths_j / depths_i
            if np.median(depth_ratios) < 0.01 or np.median(depth_ratios) > 50:  # 0.05~20 â†’ 0.01~50
                return False
        
        # ì˜¤ì°¨ ì„ê³„ê°’ ê²€ì¦ (ë” ì™„í™”ëœ ì¡°ê±´)
        pose_quality = (median_error < 15.0 and   # 8.0 â†’ 15.0
                mean_error < 20.0 and    # 10.0 â†’ 20.0
                max_error < 50.0)        # 20.0 â†’ 50.0
        
        if not pose_quality:
            print(f"      Pose quality check failed: median={median_error:.2f}, mean={mean_error:.2f}, max={max_error:.2f}")
        
        return pose_quality
    
    def _estimate_intrinsics(self, cam_id):
        """ê°œì„ ëœ ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ì¶”ì • (COLMAP ìš°ì„ )"""
        h, w = self.image_features[cam_id]['image_size']
        
        # COLMAP reconstructionì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
        try:
            colmap_cameras = self._get_colmap_intrinsics()
            if colmap_cameras and cam_id in colmap_cameras:
                camera = colmap_cameras[cam_id]
                width, height = camera.width, camera.height
                
                # PINHOLE ëª¨ë¸ ê°€ì • (fx, fy, cx, cy)
                if len(camera.params) == 4:
                    fx, fy, cx, cy = camera.params
                    # COLMAPì—ì„œ ì¶”ì •í•œ ì •í™•í•œ focal length ì‚¬ìš©
                    K = np.array([
                        [fx, 0, cx],
                        [0, fy, cy],
                        [0, 0, 1]
                    ], dtype=np.float32)
                    print(f"    Camera {cam_id}: Using COLMAP focal length (fx={fx:.1f}, fy={fy:.1f})")
                    return K
        except Exception as e:
            print(f"    Camera {cam_id}: COLMAP intrinsics failed, using default: {e}")
        
        # COLMAPì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì¶”ì • ì‚¬ìš©
        focal = max(w, h) * 0.9  # ì•½ê°„ ë³´ìˆ˜ì ì¸ ì¶”ì •
        cx, cy = w / 2, h / 2
        
        K = np.array([
            [focal, 0, cx],
            [0, focal, cy],
            [0, 0, 1]
        ], dtype=np.float32)
        
        print(f"    Camera {cam_id}: Using default focal length ({focal:.1f})")
        return K
    
    def _get_colmap_intrinsics(self):
        """COLMAP reconstructionì—ì„œ ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ì½ê¸°"""
        try:
            # COLMAP reconstruction ê²½ë¡œ í™•ì¸
            output_dir = getattr(self, 'output_dir', None)
            if output_dir is None:
                return None
            
            reconstruction_path = Path(output_dir) / "sparse" / "0"
            cameras_bin = reconstruction_path / "cameras.bin"
            
            if not cameras_bin.exists():
                return None
            
            # COLMAP reconstruction íŒŒì‹±
            from scene.colmap_loader import read_intrinsics_binary
            cameras = read_intrinsics_binary(str(cameras_bin))
            
            # ì´ë¯¸ì§€ IDì™€ ì¹´ë©”ë¼ ID ë§¤í•‘
            images_bin = reconstruction_path / "images.bin"
            if images_bin.exists():
                from scene.colmap_loader import read_extrinsics_binary
                images = read_extrinsics_binary(str(images_bin))
                
                # ì´ë¯¸ì§€ ID -> ì¹´ë©”ë¼ ID ë§¤í•‘
                image_to_camera = {}
                for image_id, image in images.items():
                    image_to_camera[image_id] = image.camera_id
                
                return image_to_camera, cameras
            
            return None
            
        except Exception as e:
            print(f"    COLMAP intrinsics ì½ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def _triangulate_all_points_robust(self):
        """ê°œì„ ëœ ì‚¼ê°ì¸¡ëŸ‰ - í’ˆì§ˆ ê¸°ë°˜ í•„í„°ë§ ê°•í™”"""
        point_id = 0
        total_matches_processed = 0
        total_valid_matches = 0
        total_triangulated = 0
        total_validated = 0
        
        print(f"  Processing {len(self.matches)} image pairs for triangulation...")
        
        for (cam_i, cam_j), matches in self.matches.items():
            if cam_i not in self.cameras or cam_j not in self.cameras:
                continue
            
            try:
                # íˆ¬ì˜ í–‰ë ¬ ìƒì„±
                P_i = self._get_projection_matrix(cam_i)
                P_j = self._get_projection_matrix(cam_j)
                
                kpts_i = self.image_features[cam_i]['keypoints']
                kpts_j = self.image_features[cam_j]['keypoints']
                
                # ğŸ”§ ê°œì„ ëœ ì‹ ë¢°ë„ ì„ê³„ê°’
                high_conf_matches = [(idx_i, idx_j, conf) for idx_i, idx_j, conf in matches if conf > 0.2]  # 0.0001 â†’ 0.2ë¡œ ê°œì„ 
                total_matches_processed += len(matches)
                
                # ì¸ë±ìŠ¤ ë²”ìœ„ ê²€ì¦
                valid_matches = []
                for idx_i, idx_j, conf in high_conf_matches:
                    if (idx_i < len(kpts_i) and idx_j < len(kpts_j) and 
                        idx_i >= 0 and idx_j >= 0):
                        valid_matches.append((idx_i, idx_j, conf))
                
                total_valid_matches += len(valid_matches)
                
                # ğŸ”§ ê°œì„ ëœ ë°°ì¹˜ ì‚¼ê°ì¸¡ëŸ‰
                if len(valid_matches) > 10:
                    batch_size = min(50, len(valid_matches))  # ë°°ì¹˜ í¬ê¸° ì¤„ì„
                    for batch_start in range(0, len(valid_matches), batch_size):
                        batch_end = min(batch_start + batch_size, len(valid_matches))
                        batch_matches = valid_matches[batch_start:batch_end]
                        
                        # ë°°ì¹˜ ì‚¼ê°ì¸¡ëŸ‰
                        pts_i_batch = np.array([kpts_i[idx_i] for idx_i, _, _ in batch_matches])
                        pts_j_batch = np.array([kpts_j[idx_j] for _, idx_j, _ in batch_matches])
                        
                        try:
                            # OpenCV ë°°ì¹˜ ì‚¼ê°ì¸¡ëŸ‰
                            points_4d = cv2.triangulatePoints(P_i, P_j, pts_i_batch.T, pts_j_batch.T)
                            
                            # 4Dì—ì„œ 3Dë¡œ ë³€í™˜ (ê°œì„ ëœ ê²€ì¦)
                            for i in range(points_4d.shape[1]):
                                point_4d = points_4d[:, i]
                                
                                if abs(point_4d[3]) < 1e-10:
                                    continue
                                
                                point_3d = (point_4d[:3] / point_4d[3]).flatten()
                                total_triangulated += 1
                                
                                # ğŸ”§ ê°œì„ ëœ ìœ íš¨ì„± ê²€ì‚¬
                                if self._is_point_valid_improved(point_3d, cam_i, cam_j, pts_i_batch[i], pts_j_batch[i]):
                                    # ìƒ‰ìƒ ì¶”ì •
                                    color = self._estimate_point_color_robust(point_3d, cam_i, batch_matches[i][0])
                                    
                                    # 3D í¬ì¸íŠ¸ ì €ì¥
                                    self.points_3d[point_id] = {
                                        'xyz': point_3d.astype(np.float32),
                                        'color': color,
                                        'observations': [(cam_i, pts_i_batch[i], batch_matches[i][2]), 
                                                        (cam_j, pts_j_batch[i], batch_matches[i][2])]
                                    }
                                    
                                    # ê´€ì°° ë°ì´í„° ì¶”ê°€
                                    self.point_observations[point_id].append((cam_i, pts_i_batch[i], batch_matches[i][2]))
                                    self.point_observations[point_id].append((cam_j, pts_j_batch[i], batch_matches[i][2]))
                                    
                                    point_id += 1
                                    total_validated += 1
                                    
                        except Exception as e:
                            print(f"    Batch triangulation failed for pair {cam_i}-{cam_j}: {e}")
                            continue
                else:
                    # ê°œë³„ ì‚¼ê°ì¸¡ëŸ‰ (ê¸°ì¡´ ë°©ì‹)
                    for idx_i, idx_j, conf in valid_matches:
                        try:
                            # ì‚¼ê°ì¸¡ëŸ‰
                            pt_i = kpts_i[idx_i].astype(np.float32)
                            pt_j = kpts_j[idx_j].astype(np.float32)
                            
                            point_4d = cv2.triangulatePoints(P_i, P_j, pt_i.reshape(2, 1), pt_j.reshape(2, 1))
                            
                            if abs(point_4d[3, 0]) < 1e-10:
                                continue
                                
                            point_3d = (point_4d[:3] / point_4d[3]).flatten()
                            total_triangulated += 1
                            
                            # ğŸ”§ ê°œì„ ëœ ìœ íš¨ì„± ê²€ì‚¬
                            if self._is_point_valid_improved(point_3d, cam_i, cam_j, pt_i, pt_j):
                                # ìƒ‰ìƒ ì¶”ì •
                                color = self._estimate_point_color_robust(point_3d, cam_i, idx_i)
                                
                                # 3D í¬ì¸íŠ¸ ì €ì¥
                                self.points_3d[point_id] = {
                                    'xyz': point_3d.astype(np.float32),
                                    'color': color,
                                    'observations': [(cam_i, pt_i, conf), (cam_j, pt_j, conf)]
                                }
                                
                                # ê´€ì°° ë°ì´í„° ì¶”ê°€
                                self.point_observations[point_id].append((cam_i, pt_i, conf))
                                self.point_observations[point_id].append((cam_j, pt_j, conf))
                                
                                point_id += 1
                                total_validated += 1
                                
                        except Exception as e:
                            continue
                        
            except Exception as e:
                print(f"    Error processing pair {cam_i}-{cam_j}: {e}")
                continue
        
        print(f"  Triangulation statistics:")
        print(f"    Total matches processed: {total_matches_processed}")
        print(f"    Valid matches: {total_valid_matches}")
        print(f"    Successfully triangulated: {total_triangulated}")
        print(f"    Passed validation: {total_validated}")
        print(f"    Final 3D points: {len(self.points_3d)}")
        
        return len(self.points_3d)

    def _is_point_valid_improved(self, point_3d, cam_i, cam_j, pt_i, pt_j):
        """ê°œì„ ëœ 3D í¬ì¸íŠ¸ ìœ íš¨ì„± ê²€ì‚¬"""
        
        # 1. ê¸°ë³¸ NaN/Inf ì²´í¬
        if np.any(np.isnan(point_3d)) or np.any(np.isinf(point_3d)):
            return False
        
        # 2. ê±°ë¦¬ ì œí•œ (ë” í˜„ì‹¤ì ì¸ ë²”ìœ„)
        distance = np.linalg.norm(point_3d)
        if distance > 100 or distance < 0.01:  # 1000 â†’ 100, 0.001 â†’ 0.01ë¡œ ê°œì„ 
            return False
        
        # 3. ê°œì„ ëœ ì¬íˆ¬ì˜ ì˜¤ì°¨ ì²´í¬
        try:
            max_reprojection_error = 0.0
            
            for cam_id, pt_observed in [(cam_i, pt_i), (cam_j, pt_j)]:
                if cam_id not in self.cameras:
                    continue
                
                cam = self.cameras[cam_id]
                K, R, T = cam['K'], cam['R'], cam['T']
                
                # ì¹´ë©”ë¼ ì¢Œí‘œê³„ë¡œ ë³€í™˜
                point_cam = R @ (point_3d - T)
                
                # ê¹Šì´ ì²´í¬ (ì¹´ë©”ë¼ ì•ìª½ì— ìˆì–´ì•¼ í•¨)
                if point_cam[2] <= 0.01:  # 0.001 â†’ 0.01ë¡œ ê°œì„ 
                    return False
                
                # ì¬íˆ¬ì˜
                point_2d_proj = K @ point_cam
                
                if abs(point_2d_proj[2]) < 1e-10:
                    return False
                    
                point_2d_proj = point_2d_proj[:2] / point_2d_proj[2]
                
                # ì¬íˆ¬ì˜ ì˜¤ì°¨ ê³„ì‚°
                error = np.linalg.norm(point_2d_proj - pt_observed)
                max_reprojection_error = max(max_reprojection_error, error)
            
            # ì¬íˆ¬ì˜ ì˜¤ì°¨ ì„ê³„ê°’ (ë” ì—„ê²©í•˜ê²Œ)
            if max_reprojection_error > 10.0:  # 100 â†’ 10ìœ¼ë¡œ ê°œì„ 
                return False
            
            return True
            
        except Exception as e:
            return False

    def _estimate_point_color_robust(self, point_3d, cam_id, kpt_idx):
        """ê°œì„ ëœ 3D í¬ì¸íŠ¸ ìƒ‰ìƒ ì¶”ì •"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì´ë¯¸ì§€ì—ì„œ ìƒ‰ìƒì„ ìƒ˜í”Œë§
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ëœë¤ ìƒ‰ìƒ ì‚¬ìš©
        return np.random.rand(3).astype(np.float32)
    
    def _bundle_adjustment_robust(self, max_iterations=50):
        """ê°œì„ ëœ Bundle Adjustment - ë” ê°•ë ¥í•œ ìµœì í™”"""
        
        n_cameras = len(self.cameras)
        n_points = len(self.points_3d)
        
        if n_cameras < 2 or n_points < 20:  # 10 â†’ 20ìœ¼ë¡œ ì¦ê°€
            print("  Insufficient data for bundle adjustment")
            return
        
        # ê´€ì°° ë°ì´í„° ìˆ˜ ê³„ì‚°
        total_observations = sum(len(obs) for obs in self.point_observations.values())
        n_residuals = total_observations * 2  # ê° ê´€ì°°ë‹¹ 2ê°œ ì”ì°¨ (x, y)
        n_variables = n_cameras * 6 + n_points * 3  # ì¹´ë©”ë¼ 6DOF + í¬ì¸íŠ¸ 3DOF
        
        print(f"  BA Statistics:")
        print(f"    Cameras: {n_cameras}, Points: {n_points}")
        print(f"    Observations: {total_observations}")
        print(f"    Residuals: {n_residuals}, Variables: {n_variables}")
        
        # ğŸ”§ ê°œì„ ëœ ë°©ë²• ì„ íƒ
        if n_residuals < n_variables * 2:  # 2ë°° ì´ìƒì˜ ì”ì°¨ê°€ í•„ìš”
            print(f"  âš ï¸  Under-constrained problem: {n_residuals} residuals < {n_variables * 2} (2x variables)")
            print("  Using 'trf' method with conservative settings")
            method = 'trf'
        else:
            print("  Using 'lm' method")
            method = 'lm'
        
        try:
            params = self._pack_parameters()
        except Exception as e:
            print(f"  Parameter packing failed: {e}")
            return
        
        try:
            # ğŸ”§ ê°œì„ ëœ BA ì„¤ì •
            if method == 'trf':
                result = least_squares(
                    self._compute_residuals_improved,
                    params,
                    method='trf',
                    max_nfev=max_iterations * 2,
                    verbose=1,
                    ftol=1e-6,  # ë” ì—„ê²©í•œ ìˆ˜ë ´ ì¡°ê±´
                    xtol=1e-6,
                    bounds=(-np.inf, np.inf)
                )
            else:
                result = least_squares(
                    self._compute_residuals_improved,
                    params,
                    method='lm',
                    max_nfev=max_iterations * 3,
                    verbose=1,
                    ftol=1e-7,  # ë” ì—„ê²©í•œ ìˆ˜ë ´ ì¡°ê±´
                    xtol=1e-7
                )
            
            # ê²°ê³¼ ì–¸íŒ¨í‚¹
            self._unpack_parameters(result.x)
            
            print(f"  Bundle adjustment completed. Final cost: {result.cost:.6f}")
            print(f"  Method: {method}, Iterations: {result.nfev}")
            
            # ğŸ”§ ê°œì„ ëœ cost í‰ê°€
            if result.cost > 500:
                print(f"  âš ï¸  ë†’ì€ BA cost: {result.cost:.2f}")
                print("  í¬ì¸íŠ¸ í´ë¼ìš°ë“œ í’ˆì§ˆì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            elif result.cost > 50:
                print(f"  âš ï¸  ì¤‘ê°„ BA cost: {result.cost:.2f}")
            else:
                print(f"  âœ… ì¢‹ì€ BA cost: {result.cost:.2f}")
            
        except Exception as e:
            print(f"  Bundle adjustment failed: {e}")
            print("  Continuing without bundle adjustment...")

    def _compute_residuals_improved(self, params):
        """ê°œì„ ëœ Bundle Adjustment ì”ì°¨ ê³„ì‚°"""
        residuals = []
        
        # íŒŒë¼ë¯¸í„° ì–¸íŒ¨í‚¹
        try:
            self._unpack_parameters(params)
        except Exception as e:
            print(f"    Warning: Parameter unpacking failed: {e}")
            return np.ones(100) * 1e6
        
        # ê° ê´€ì°°ì— ëŒ€í•œ ì¬íˆ¬ì˜ ì˜¤ì°¨ ê³„ì‚°
        for point_id, observations in self.point_observations.items():
            if point_id not in self.points_3d:
                continue
                
            point_3d = self.points_3d[point_id]['xyz']
            
            for cam_id, observed_pt, conf in observations:
                if cam_id not in self.cameras:
                    continue
                
                try:
                    cam = self.cameras[cam_id]
                    K = cam['K']
                    R = cam['R']
                    T = cam['T']
                    
                    # ì¹´ë©”ë¼ ì¢Œí‘œê³„ë¡œ ë³€í™˜
                    point_cam = R @ (point_3d - T)
                    
                    # ê¹Šì´ ì²´í¬
                    if point_cam[2] <= 0:
                        residuals.extend([20.0, 20.0])  # ì¹´ë©”ë¼ ë’¤ìª½ (ë” ì‘ì€ í˜ë„í‹°)
                        continue
                    
                    # ì¬íˆ¬ì˜
                    point_2d_proj = K @ point_cam
                    if abs(point_2d_proj[2]) < 1e-10:
                        residuals.extend([20.0, 20.0])
                        continue
                    point_2d_proj = point_2d_proj[:2] / point_2d_proj[2]
                    
                    # ğŸ”§ ê°œì„ ëœ ì”ì°¨ ê³„ì‚°
                    residual = point_2d_proj - observed_pt
                    
                    # ğŸ”§ Huber loss ì ìš© (ì´ìƒì¹˜ì— ê°•í•¨)
                    residual = self._apply_huber_loss_improved(residual, delta=3.0)
                    
                    # ğŸ”§ ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜ (ë” í˜„ì‹¤ì ì¸ ê°€ì¤‘ì¹˜)
                    weight = np.clip(conf, 0.1, 1.0)
                    
                    # ğŸ”§ ìŠ¤ì¼€ì¼ë§ (í”½ì…€ ë‹¨ìœ„ë¥¼ ì ì ˆí•œ ìŠ¤ì¼€ì¼ë¡œ)
                    residual = residual * weight * 0.05  # ìŠ¤ì¼€ì¼ë§ íŒ©í„° ì¡°ì •
                    
                    residuals.extend(residual)
                    
                except Exception as e:
                    residuals.extend([5.0, 5.0])  # ë” ì‘ì€ ê¸°ë³¸ ì˜¤ì°¨
        
        if len(residuals) == 0:
            return np.ones(100) * 1e6
        
        residuals = np.array(residuals)
        
        # NaNì´ë‚˜ ë¬´í•œëŒ€ ê°’ ì²´í¬
        if np.any(np.isnan(residuals)) or np.any(np.isinf(residuals)):
            return np.ones(len(residuals)) * 1e6
        
        return residuals

    def _apply_huber_loss_improved(self, residual, delta=3.0):
        """ê°œì„ ëœ Huber loss ì ìš©"""
        abs_residual = np.abs(residual)
        mask = abs_residual <= delta
        
        result = np.zeros_like(residual)
        result[mask] = residual[mask]
        result[~mask] = delta * np.sign(residual[~mask]) * (2 * np.sqrt(abs_residual[~mask] / delta) - 1)
        
        return result
    
    def _expand_point_observations(self):
        """í¬ì¸íŠ¸ ê´€ì°° ë°ì´í„° í™•ì¥ìœ¼ë¡œ ì”ì°¨ ìˆ˜ ì¦ê°€"""
        
        print("  Expanding point observations...")
        
        original_obs = sum(len(obs) for obs in self.point_observations.values())
        
        # ê° 3D í¬ì¸íŠ¸ì— ëŒ€í•´ ë‹¤ë¥¸ ì¹´ë©”ë¼ì—ì„œì˜ ì¬íˆ¬ì˜ í™•ì¸
        for point_id, point_data in self.points_3d.items():
            point_3d = point_data['xyz']
            current_cams = set([obs[0] for obs in self.point_observations[point_id]])
            
            # ë‹¤ë¥¸ ì¹´ë©”ë¼ë“¤ì—ì„œë„ ì´ í¬ì¸íŠ¸ê°€ ë³´ì´ëŠ”ì§€ í™•ì¸
            for cam_id in self.cameras:
                if cam_id in current_cams:
                    continue
                
                try:
                    # ì¬íˆ¬ì˜ ê³„ì‚°
                    cam = self.cameras[cam_id]
                    K, R, T = cam['K'], cam['R'], cam['T']
                    
                    point_cam = R @ (point_3d - T)
                    if point_cam[2] <= 0:  # ì¹´ë©”ë¼ ë’¤ìª½
                        continue
                    
                    point_2d_proj = K @ point_cam
                    point_2d_proj = point_2d_proj[:2] / point_2d_proj[2]
                    
                    # ì´ë¯¸ì§€ ê²½ê³„ í™•ì¸
                    h, w = self.image_features[cam_id]['image_size']
                    if (0 <= point_2d_proj[0] < w and 0 <= point_2d_proj[1] < h):
                        
                        # í•´ë‹¹ ì¹´ë©”ë¼ì˜ í‚¤í¬ì¸íŠ¸ì™€ ê°€ê¹Œìš´ì§€ í™•ì¸
                        kpts = self.image_features[cam_id]['keypoints']
                        distances = np.linalg.norm(kpts - point_2d_proj, axis=1)
                        min_idx = np.argmin(distances)
                        
                        if distances[min_idx] < 30.0:  # 30 í”½ì…€ ë‚´
                            # ê´€ì°° ì¶”ê°€
                            confidence = 0.1  # ë‚®ì€ ì‹ ë¢°ë„
                            self.point_observations[point_id].append((cam_id, point_2d_proj, confidence))
                            
                except Exception:
                    continue
        
        expanded_obs = sum(len(obs) for obs in self.point_observations.values())
        print(f"    Expanded observations: {original_obs} â†’ {expanded_obs}")
    
    def _rotation_matrix_to_angle_axis(self, R):
        """íšŒì „ í–‰ë ¬ì„ ë¡œë“œë¦¬ê²ŒìŠ¤ ë²¡í„°ë¡œ ë³€í™˜"""
        # ê°„ë‹¨í•œ êµ¬í˜„ (ì‹¤ì œë¡œëŠ” ë” ì •í™•í•œ ë³€í™˜ì´ í•„ìš”)
        trace = np.trace(R)
        if trace > 3 - 1e-6:
            return np.zeros(3)
        
        angle = np.arccos((trace - 1) / 2)
        axis = np.array([
            R[2, 1] - R[1, 2],
            R[0, 2] - R[2, 0],
            R[1, 0] - R[0, 1]
        ])
        
        if np.linalg.norm(axis) > 1e-6:
            axis = axis / np.linalg.norm(axis)
        
        return angle * axis
    
    def _angle_axis_to_rotation_matrix(self, angle_axis):
        """ë¡œë“œë¦¬ê²ŒìŠ¤ ë²¡í„°ë¥¼ íšŒì „ í–‰ë ¬ë¡œ ë³€í™˜"""
        angle = np.linalg.norm(angle_axis)
        if angle < 1e-6:
            return np.eye(3)
        
        axis = angle_axis / angle
        K = np.array([
            [0, -axis[2], axis[1]],
            [axis[2], 0, -axis[0]],
            [-axis[1], axis[0], 0]
        ])
        
        R = np.eye(3) + np.sin(angle) * K + (1 - np.cos(angle)) * (K @ K)
        return R
    
    def _refine_point_cloud(self):
        """í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì •ì œ (ë” ì™„í™”ëœ ë²„ì „)"""
        print(f"  Refining point cloud...")
        
        # 1. ì¤‘ë³µ í¬ì¸íŠ¸ ì œê±° (ë” ì™„í™”ëœ ì¡°ê±´)
        points_to_remove = set()
        points_list = list(self.points_3d.items())
        
        for i, (id1, point1) in enumerate(points_list):
            for j, (id2, point2) in enumerate(points_list[i+1:], i+1):
                if id1 in points_to_remove or id2 in points_to_remove:
                    continue
                
                dist = np.linalg.norm(point1['xyz'] - point2['xyz'])
                if dist < 0.0001:  # 0.001 â†’ 0.0001ë¡œ ë” ì—„ê²©í•˜ê²Œ
                    points_to_remove.add(id2)
        
        # ì¤‘ë³µ í¬ì¸íŠ¸ ì œê±°
        for point_id in points_to_remove:
            del self.points_3d[point_id]
            if point_id in self.point_observations:
                del self.point_observations[point_id]
        
        print(f"  Removed {len(points_to_remove)} duplicate points")
        print(f"  Final point cloud: {len(self.points_3d)} points")
    
    def _get_projection_matrix(self, cam_id):
        """ì¹´ë©”ë¼ íˆ¬ì˜ í–‰ë ¬ ìƒì„± (ìˆ˜ì •ëœ ë²„ì „)"""
        cam = self.cameras[cam_id]
        K, R, T = cam['K'], cam['R'], cam['T']
        
        # Tê°€ ì›”ë“œ ì¢Œí‘œê³„ì˜ ì¹´ë©”ë¼ ì¤‘ì‹¬ì´ë¼ê³  ê°€ì •
        # P = K[R|t] where t = -R * T (ì¹´ë©”ë¼ ì¤‘ì‹¬ì„ ì¹´ë©”ë¼ ì¢Œí‘œê³„ë¡œ ë³€í™˜)
        t = -R @ T  # ì¹´ë©”ë¼ ì¤‘ì‹¬ì„ ì¹´ë©”ë¼ ì¢Œí‘œê³„ë¡œ ë³€í™˜
        RT = np.hstack([R, t.reshape(-1, 1)])
        P = K @ RT
        
        return P
    
    def _create_3dgs_scene_info(self, image_paths):
        """3DGSìš© SceneInfo ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
        
        # Lazy import 3DGS modules
        CameraInfo, SceneInfo, BasicPointCloud = get_3dgs_imports()
        if CameraInfo is None:
            raise ImportError("3DGS modules not available")
        
        # CameraInfo ë¦¬ìŠ¤íŠ¸ ìƒì„±
        cam_infos = []
        for cam_id in sorted(self.cameras.keys()):
            cam = self.cameras[cam_id]
            image_path = self.image_features[cam_id]['image_path']
            h, w = self.image_features[cam_id]['image_size']
            
            # FoV ê³„ì‚°
            K = cam['K']
            focal_x, focal_y = K[0, 0], K[1, 1]
            FovX = 2 * np.arctan(w / (2 * focal_x))
            FovY = 2 * np.arctan(h / (2 * focal_y))
            
            # ë” ë‚˜ì€ í…ŒìŠ¤íŠ¸ ë¶„í•  (ì—°ê²°ì„± ê¸°ë°˜)
            is_test = self._should_be_test_camera(cam_id)
            
            cam_info = CameraInfo(
                uid=cam_id,
                R=cam['R'],
                T=cam['T'],
                FovY=float(FovY),
                FovX=float(FovX),
                image_path=image_path,
                image_name=Path(image_path).name,
                width=w,
                height=h,
                depth_params=None,
                depth_path="",
                is_test=is_test
            )
            cam_infos.append(cam_info)
        
        # í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
        if self.points_3d:
            points = np.array([pt['xyz'] for pt in self.points_3d.values()])
            colors = np.array([pt['color'] for pt in self.points_3d.values()])
            
            # ë²•ì„  ë²¡í„° (ê°œì„ ëœ ê³„ì‚°)
            normals = self._compute_point_normals(points)
            
            pcd = BasicPointCloud(points=points, colors=colors, normals=normals)
        else:
            # ê¸°ë³¸ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ (ë” ë§ì€ ìˆ˜)
            n_points = 25000  # 15000 â†’ 25000ë¡œ ì¦ê°€
            points = np.random.randn(n_points, 3).astype(np.float32) * 4  # 3 â†’ 4ë¡œ ì¦ê°€
            colors = np.random.rand(n_points, 3).astype(np.float32)
            normals = np.random.randn(n_points, 3).astype(np.float32)
            normals = normals / np.linalg.norm(normals, axis=1, keepdims=True)
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        train_cams = [c for c in cam_infos if not c.is_test]
        test_cams = [c for c in cam_infos if c.is_test]
        
        # NeRF ì •ê·œí™”
        nerf_norm = self._compute_nerf_normalization(train_cams)
        
        return SceneInfo(
            point_cloud=pcd,
            train_cameras=train_cams,
            test_cameras=test_cams,
            nerf_normalization=nerf_norm,
            ply_path="",
            is_nerf_synthetic=False
        )
    
    def _should_be_test_camera(self, cam_id):
        """ë” ë‚˜ì€ í…ŒìŠ¤íŠ¸ ì¹´ë©”ë¼ ì„ íƒ"""
        # ì—°ê²°ì„±ì´ ë‚®ì€ ì¹´ë©”ë¼ë¥¼ í…ŒìŠ¤íŠ¸ë¡œ ì„ íƒ
        connectivity = len(self.camera_graph.get(cam_id, []))
        
        # ì—°ê²°ì„±ì´ 1 ì´í•˜ì´ê±°ë‚˜, íŠ¹ì • ê°„ê²©ìœ¼ë¡œ ì„ íƒ
        if connectivity <= 1:
            return True
        
        # 10ê°œë§ˆë‹¤ 1ê°œì”© í…ŒìŠ¤íŠ¸ë¡œ ì„ íƒ (ì—°ê²°ì„±ì´ ë†’ì€ ì¹´ë©”ë¼ë“¤ ì¤‘ì—ì„œ)
        if cam_id % 10 == 0 and connectivity >= 2:
            return True
        
        return False
    
    def _compute_point_normals(self, points):
        """í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë²•ì„  ë²¡í„° ê³„ì‚°"""
        if len(points) < 3:
            return np.random.randn(len(points), 3).astype(np.float32)
        
        # ê°„ë‹¨í•œ ë²•ì„  ê³„ì‚° (sklearn ì˜ì¡´ì„± ì œê±°)
        try:
            normals = np.zeros_like(points)
            
            for i in range(len(points)):
                # í˜„ì¬ í¬ì¸íŠ¸
                current_point = points[i]
                
                # ë‹¤ë¥¸ ëª¨ë“  í¬ì¸íŠ¸ì™€ì˜ ê±°ë¦¬ ê³„ì‚°
                distances = np.linalg.norm(points - current_point, axis=1)
                
                # ê°€ì¥ ê°€ê¹Œìš´ 10ê°œ í¬ì¸íŠ¸ ì„ íƒ (ìê¸° ìì‹  ì œì™¸)
                nearest_indices = np.argsort(distances)[1:11]  # ìê¸° ìì‹  ì œì™¸
                
                if len(nearest_indices) < 3:
                    normals[i] = np.random.randn(3)
                    continue
                
                # ì´ì›ƒ í¬ì¸íŠ¸ë“¤ì˜ ì¤‘ì‹¬ ê³„ì‚°
                neighbors = points[nearest_indices]
                centroid = np.mean(neighbors, axis=0)
                
                # ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚°
                centered = neighbors - centroid
                cov_matrix = centered.T @ centered
                
                # ê°€ì¥ ì‘ì€ ê³ ìœ ê°’ì— í•´ë‹¹í•˜ëŠ” ê³ ìœ ë²¡í„°ê°€ ë²•ì„ 
                eigenvals, eigenvecs = np.linalg.eigh(cov_matrix)
                normal = eigenvecs[:, 0]  # ê°€ì¥ ì‘ì€ ê³ ìœ ê°’
                
                # ë°©í–¥ ì¼ê´€ì„± í™•ì¸
                if normal[2] < 0:
                    normal = -normal
                
                normals[i] = normal
            
            # ì •ê·œí™”
            norms = np.linalg.norm(normals, axis=1, keepdims=True)
            norms[norms == 0] = 1
            normals = normals / norms
            
        except Exception as e:
            print(f"    Warning: Normal computation failed: {e}")
            # ì‹¤íŒ¨ì‹œ ëœë¤ ë²•ì„ 
            normals = np.random.randn(len(points), 3).astype(np.float32)
            normals = normals / np.linalg.norm(normals, axis=1, keepdims=True)
        
        return normals.astype(np.float32)
    
    def _create_default_pointcloud(self):
        """ê¸°ë³¸ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
        # Lazy import 3DGS modules
        _, _, BasicPointCloud = get_3dgs_imports()
        if BasicPointCloud is None:
            # Fallback: ê°„ë‹¨í•œ í´ë˜ìŠ¤ ì •ì˜
            class BasicPointCloud:
                def __init__(self, points, colors, normals):
                    self.points = points
                    self.colors = colors
                    self.normals = normals
        
        # ì¹´ë©”ë¼ ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë” í˜„ì‹¤ì ì¸ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ
        if len(self.cameras) > 0:
            # ì¹´ë©”ë¼ ì¤‘ì‹¬ ê³„ì‚°
            camera_centers = []
            for cam_id in self.cameras:
                R, T = self.cameras[cam_id]['R'], self.cameras[cam_id]['T']
                center = -R.T @ T
                camera_centers.append(center)
            
            if camera_centers:
                camera_centers = np.array(camera_centers)
                center_mean = np.mean(camera_centers, axis=0)
                center_std = np.std(camera_centers, axis=0)
                
                # ì‹¤ì œ í¬ì¸íŠ¸ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
                if self.points_3d:
                    actual_points = np.array([pt['xyz'] for pt in self.points_3d.values()])
                    if len(actual_points) > 0:
                        # ì‹¤ì œ í¬ì¸íŠ¸ ì£¼ë³€ì— ì¶”ê°€ í¬ì¸íŠ¸ ìƒì„±
                        n_additional = 15000  # ë” ë§ì€ ì¶”ê°€ í¬ì¸íŠ¸ (5000 â†’ 15000)
                        points = np.random.randn(n_additional, 3).astype(np.float32)
                        points = points * np.std(actual_points, axis=0) * 0.8 + np.mean(actual_points, axis=0)
                        
                        # ì‹¤ì œ í¬ì¸íŠ¸ì™€ í•©ì¹˜ê¸°
                        points = np.vstack([actual_points, points])
                        colors = np.random.rand(len(points), 3).astype(np.float32)
                        normals = self._compute_point_normals(points)
                    else:
                        # ì¹´ë©”ë¼ ë¶„í¬ë¥¼ ê³ ë ¤í•œ í¬ì¸íŠ¸ ìƒì„±
                        n_points = 20000  # ë” ë§ì€ ìˆ˜ (10000 â†’ 20000)
                        points = np.random.randn(n_points, 3).astype(np.float32)
                        points = points * center_std * 0.8 + center_mean
                        colors = np.random.rand(n_points, 3).astype(np.float32)
                        normals = self._compute_point_normals(points)
                else:
                    # ì¹´ë©”ë¼ ë¶„í¬ë¥¼ ê³ ë ¤í•œ í¬ì¸íŠ¸ ìƒì„±
                    n_points = 20000  # ë” ë§ì€ ìˆ˜ (10000 â†’ 20000)
                    points = np.random.randn(n_points, 3).astype(np.float32)
                    points = points * center_std * 0.8 + center_mean
                    colors = np.random.rand(n_points, 3).astype(np.float32)
                    normals = self._compute_point_normals(points)
            else:
                # ê¸°ë³¸ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ (ë” ì ì€ ìˆ˜)
                points = np.random.randn(10000, 3).astype(np.float32) * 3
                colors = np.random.rand(10000, 3).astype(np.float32)
                normals = np.random.randn(10000, 3).astype(np.float32)
                normals = normals / np.linalg.norm(normals, axis=1, keepdims=True)
        else:
            # ê¸°ë³¸ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ (ë” ì ì€ ìˆ˜)
            points = np.random.randn(10000, 3).astype(np.float32) * 3
            colors = np.random.rand(10000, 3).astype(np.float32)
            normals = np.random.randn(10000, 3).astype(np.float32)
            normals = normals / np.linalg.norm(normals, axis=1, keepdims=True)
        
        return BasicPointCloud(points=points, colors=colors, normals=normals)
    
    def _compute_nerf_normalization(self, cam_infos):
        """NeRF ì •ê·œí™” íŒŒë¼ë¯¸í„° ê³„ì‚° (ê°œì„ ëœ ë²„ì „)"""
        # Lazy import 3DGS modules
        try:
            from utils.graphics_utils import getWorld2View2
        except ImportError:
            # Fallback: ê°„ë‹¨í•œ í•¨ìˆ˜ ì •ì˜
            def getWorld2View2(R, t):
                Rt = np.zeros((4, 4))
                Rt[:3, :3] = R
                Rt[:3, 3] = t
                Rt[3, 3] = 1.0
                return Rt
        
        if not cam_infos:
            return {"translate": np.zeros(3), "radius": 1.0}
        
        # ì¹´ë©”ë¼ ì¤‘ì‹¬ ê³„ì‚°
        cam_centers = []
        for cam in cam_infos:
            W2C = getWorld2View2(cam.R, cam.T)
            C2W = np.linalg.inv(W2C)
            cam_centers.append(C2W[:3, 3:4])
        
        cam_centers = np.hstack(cam_centers)
        
        # ë” ì•ˆì •ì ì¸ ì¤‘ì‹¬ ê³„ì‚° (ì¤‘ê°„ê°’ ì‚¬ìš©)
        center = np.median(cam_centers, axis=1, keepdims=True).flatten()
        
        # ê±°ë¦¬ ê³„ì‚°
        distances = np.linalg.norm(cam_centers - center.reshape(-1, 1), axis=0)
        
        # ë” ë³´ìˆ˜ì ì¸ ë°˜ì§€ë¦„ ê³„ì‚° (95 í¼ì„¼íƒ€ì¼ ì‚¬ìš©)
        radius = np.percentile(distances, 95) * 1.2
        
        # ìµœì†Œ ë°˜ì§€ë¦„ ë³´ì¥
        radius = max(radius, 1.0)
        
        return {"translate": -center, "radius": radius}
    
    def _save_3dgs_format(self, scene_info, output_dir):
        """3DGS í•™ìŠµì„ ìœ„í•œ íŒŒì¼ êµ¬ì¡° ìƒì„±"""
        output_dir = Path(output_dir)
        output_dir.mkdir(exist_ok=True, parents=True)
        
        # COLMAP í˜¸í™˜ ë””ë ‰í† ë¦¬ êµ¬ì¡°
        sparse_dir = output_dir / "sparse" / "0"
        sparse_dir.mkdir(exist_ok=True, parents=True)
        
        images_dir = output_dir / "images"
        images_dir.mkdir(exist_ok=True)
        
        # 1. ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ì €ì¥ (cameras.txt)
        self._write_cameras_txt(scene_info.train_cameras + scene_info.test_cameras, 
                               sparse_dir / "cameras.txt")
        
        # 2. ì¹´ë©”ë¼ í¬ì¦ˆ ì €ì¥ (images.txt)
        self._write_images_txt(scene_info.train_cameras + scene_info.test_cameras, 
                              sparse_dir / "images.txt")
        
        # 3. 3D í¬ì¸íŠ¸ ì €ì¥ (points3D.ply)
        self._write_points3d_ply(scene_info.point_cloud, sparse_dir / "points3D.ply")
        
        # 4. ì´ë¯¸ì§€ ë³µì‚¬ ë˜ëŠ” ì‹¬ë³¼ë¦­ ë§í¬
        self._setup_images_directory(scene_info.train_cameras + scene_info.test_cameras, 
                                    images_dir)
        
        print(f"  3DGS-compatible files saved to {output_dir}")
        print(f"  Use: python train.py -s {output_dir} -m {output_dir}/3dgs_output")
    
    def _write_cameras_txt(self, cam_infos, output_path):
        """COLMAP í˜•ì‹ cameras.txt ìƒì„±"""
        with open(output_path, 'w') as f:
            f.write("# Camera list with one line of data per camera:\n")
            f.write("# CAMERA_ID, MODEL, WIDTH, HEIGHT, PARAMS[]\n")
            f.write(f"# Number of cameras: {len(cam_infos)}\n")
            
            for cam in cam_infos:
                # PINHOLE ëª¨ë¸ ì‚¬ìš©
                focal_x = cam.width / (2 * np.tan(cam.FovX / 2))
                focal_y = cam.height / (2 * np.tan(cam.FovY / 2))
                cx, cy = cam.width / 2, cam.height / 2
                
                f.write(f"{cam.uid} PINHOLE {cam.width} {cam.height} "
                       f"{focal_x:.6f} {focal_y:.6f} {cx:.6f} {cy:.6f}\n")
    
    def _write_images_txt(self, cam_infos, output_path):
        """COLMAP í˜•ì‹ images.txt ìƒì„±"""
        with open(output_path, 'w') as f:
            f.write("# Image list with two lines of data per image:\n")
            f.write("# IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME\n")
            f.write("# POINTS2D[] as (X, Y, POINT3D_ID)\n")
            f.write(f"# Number of images: {len(cam_infos)}\n")
            
            for cam in cam_infos:
                # íšŒì „ í–‰ë ¬ì„ ì¿¼í„°ë‹ˆì–¸ìœ¼ë¡œ ë³€í™˜
                R = cam.R
                trace = np.trace(R)
                
                if trace > 0:
                    s = np.sqrt(trace + 1.0) * 2  # s = 4 * qw
                    qw = 0.25 * s
                    qx = (R[2, 1] - R[1, 2]) / s
                    qy = (R[0, 2] - R[2, 0]) / s
                    qz = (R[1, 0] - R[0, 1]) / s
                else:
                    # ì•ˆì •ì ì¸ ì¿¼í„°ë‹ˆì–¸ ë³€í™˜
                    qw = np.sqrt(1 + R[0,0] + R[1,1] + R[2,2]) / 2
                    qx = (R[2,1] - R[1,2]) / (4 * qw) if qw != 0 else 0
                    qy = (R[0,2] - R[2,0]) / (4 * qw) if qw != 0 else 0
                    qz = (R[1,0] - R[0,1]) / (4 * qw) if qw != 0 else 0
                
                # ì •ê·œí™”
                q_norm = np.sqrt(qw*qw + qx*qx + qy*qy + qz*qz)
                if q_norm > 0:
                    qw, qx, qy, qz = qw/q_norm, qx/q_norm, qy/q_norm, qz/q_norm
                
                f.write(f"{cam.uid} {qw:.6f} {qx:.6f} {qy:.6f} {qz:.6f} "
                       f"{cam.T[0]:.6f} {cam.T[1]:.6f} {cam.T[2]:.6f} "
                       f"{cam.uid} {cam.image_name}\n")
                f.write("\n")  # ë¹ˆ íŠ¹ì§•ì  ë¼ì¸
    
    def _write_points3d_ply(self, point_cloud, output_path):
        """PLY í˜•ì‹ìœ¼ë¡œ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì €ì¥"""
        points = point_cloud.points
        colors = (point_cloud.colors * 255).astype(np.uint8)
        
        with open(output_path, 'w') as f:
            # PLY í—¤ë”
            f.write("ply\n")
            f.write("format ascii 1.0\n")
            f.write(f"element vertex {len(points)}\n")
            f.write("property float x\n")
            f.write("property float y\n")
            f.write("property float z\n")
            f.write("property float nx\n")
            f.write("property float ny\n")
            f.write("property float nz\n")
            f.write("property uchar red\n")
            f.write("property uchar green\n")
            f.write("property uchar blue\n")
            f.write("end_header\n")
            
            # ë°ì´í„°
            for i in range(len(points)):
                x, y, z = points[i]
                nx, ny, nz = point_cloud.normals[i]
                r, g, b = colors[i]
                f.write(f"{x:.6f} {y:.6f} {z:.6f} "
                       f"{nx:.6f} {ny:.6f} {nz:.6f} "
                       f"{r} {g} {b}\n")
    
    def _setup_images_directory(self, cam_infos, images_dir):
        """ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ì„¤ì • (ì‹¬ë³¼ë¦­ ë§í¬ ë˜ëŠ” ë³µì‚¬)"""
        import shutil
        
        for cam in cam_infos:
            src_path = Path(cam.image_path)
            dst_path = images_dir / cam.image_name
            
            if not dst_path.exists():
                try:
                    # ì‹¬ë³¼ë¦­ ë§í¬ ì‹œë„
                    dst_path.symlink_to(src_path.resolve())
                except (OSError, NotImplementedError):
                    # ì‹¤íŒ¨ì‹œ ë³µì‚¬
                    shutil.copy2(src_path, dst_path)
    
    def _load_image(self, image_path, resize=None):
        """ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬ - ì ì‘í˜• resize ì ìš©"""
        try:
            image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)
            if image is None:
                print(f"    Warning: Failed to load {image_path}")
                return None
            
            # ì ì‘í˜• resize ê³„ì‚°
            if resize is None:
                resize = self._calculate_adaptive_resize(image_path)
            
            # í¬ê¸° ì¡°ì • (SuperGlue ì²˜ë¦¬ìš©)
            if resize is None:
                pass  # ì›ë³¸ í¬ê¸° ìœ ì§€
            elif len(resize) == 2:
                image = cv2.resize(image, resize)
            elif len(resize) == 1 and resize[0] > 0:
                h, w = image.shape
                scale = resize[0] / max(h, w)
                new_h, new_w = int(h * scale), int(w * scale)
                image = cv2.resize(image, (new_w, new_h))
            
            return image.astype(np.float32)
        
        except Exception as e:
            print(f"    Error loading {image_path}: {e}")
            return None
    
    def _calculate_adaptive_resize(self, image_path):
        """ì´ë¯¸ì§€ í•´ìƒë„ì— ë”°ë¥¸ ì ì‘í˜• resize ê³„ì‚°"""
        try:
            img = cv2.imread(str(image_path))
            if img is None:
                return [1024, 768]  # ê¸°ë³¸ê°’
            
            h, w = img.shape[:2]
            max_dim = max(h, w)
            
            # ì ì‘í˜• resize ê·œì¹™
            if max_dim <= 1024:
                # ì‘ì€ ì´ë¯¸ì§€ëŠ” ì›ë³¸ í¬ê¸° ìœ ì§€
                return None
            elif max_dim <= 2048:
                # ì¤‘ê°„ í¬ê¸°ëŠ” 1024ë¡œ resize
                scale = 1024 / max_dim
                return [int(w * scale), int(h * scale)]
            else:
                # í° ì´ë¯¸ì§€ëŠ” 1536ë¡œ resize
                scale = 1536 / max_dim
                return [int(w * scale), int(h * scale)]
        except:
            return [1024, 768]  # ê¸°ë³¸ê°’

    def _pack_parameters(self):
        """ì¹´ë©”ë¼ í¬ì¦ˆì™€ 3D í¬ì¸íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ íŒ¨í‚¹"""
        params = []
        
        # ì¹´ë©”ë¼ í¬ì¦ˆ (íšŒì „ + ì´ë™)
        for cam_id in sorted(self.cameras.keys()):
            cam = self.cameras[cam_id]
            R = cam['R']
            T = cam['T']
            
            # íšŒì „ í–‰ë ¬ì„ ë¡œë“œë¦¬ê²ŒìŠ¤ ë²¡í„°ë¡œ ë³€í™˜
            angle_axis = self._rotation_matrix_to_angle_axis(R)
            params.extend(angle_axis)
            params.extend(T)
        
        # 3D í¬ì¸íŠ¸
        for point_id in sorted(self.points_3d.keys()):
            point = self.points_3d[point_id]['xyz']
            params.extend(point)
        
        params = np.array(params)
        
        # NaNì´ë‚˜ ë¬´í•œëŒ€ ê°’ ì²´í¬
        if np.any(np.isnan(params)) or np.any(np.isinf(params)):
            raise ValueError("Invalid parameters detected (NaN or Inf)")
        
        return params
    
    def _unpack_parameters(self, params):
        """ë²¡í„°ì—ì„œ ì¹´ë©”ë¼ í¬ì¦ˆì™€ 3D í¬ì¸íŠ¸ ì–¸íŒ¨í‚¹"""
        idx = 0
        
        # ì¹´ë©”ë¼ í¬ì¦ˆ ë³µì›
        for cam_id in sorted(self.cameras.keys()):
            # ë¡œë“œë¦¬ê²ŒìŠ¤ ë²¡í„° (3ê°œ)
            angle_axis = params[idx:idx+3]
            idx += 3
            
            # ì´ë™ ë²¡í„° (3ê°œ)
            T = params[idx:idx+3]
            idx += 3
            
            # íšŒì „ í–‰ë ¬ë¡œ ë³€í™˜
            R = self._angle_axis_to_rotation_matrix(angle_axis)
            
            self.cameras[cam_id]['R'] = R.astype(np.float32)
            self.cameras[cam_id]['T'] = T.astype(np.float32)
        
        # 3D í¬ì¸íŠ¸ ë³µì›
        for point_id in sorted(self.points_3d.keys()):
            xyz = params[idx:idx+3]
            idx += 3
            self.points_3d[point_id]['xyz'] = xyz.astype(np.float32)

def readSuperGlueSceneInfo(path, images, eval, train_test_exp=False, llffhold=8, 
                          superglue_config="outdoor", max_images=100):
    """SuperGlue ê¸°ë°˜ ì™„ì „í•œ SfMìœ¼ë¡œ SceneInfo ìƒì„±"""
    
    print("=== SuperGlue Complete SfM Pipeline ===")
    
    # ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
    images_folder = Path(path) / (images if images else "images")
    output_folder = Path(path) / "superglue_sfm_output"
    
    # SuperGlue ì„¤ì • (ë” ì™„í™”ëœ ì„¤ì •)
    config = {
        'superpoint': {
            'nms_radius': 3,  # 4 â†’ 3ìœ¼ë¡œ ì™„í™”
            'keypoint_threshold': 0.001,  # 0.005 â†’ 0.001ë¡œ ëŒ€í­ ì™„í™”
            'max_keypoints': 8192  # 4096 â†’ 8192ë¡œ ì¦ê°€
        },
        'superglue': {
            'weights': superglue_config,  # 'indoor' ë˜ëŠ” 'outdoor'
            'sinkhorn_iterations': 15,  # 20 â†’ 15ë¡œ ì™„í™”
            'match_threshold': 0.05,  # 0.1 â†’ 0.05ë¡œ ì™„í™”
        }
    }
    
    # SuperGlue 3DGS íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = SuperGlue3DGSPipeline(config)
    
    try:
        scene_info = pipeline.process_images_to_3dgs(
            image_dir=images_folder,
            output_dir=output_folder,
            max_images=max_images
        )
        
        print(f"\n=== SuperGlue SfM Results ===")
        print(f"Training cameras: {len(scene_info.train_cameras)}")
        print(f"Test cameras: {len(scene_info.test_cameras)}")
        print(f"3D points: {len(scene_info.point_cloud.points)}")
        print(f"Scene radius: {scene_info.nerf_normalization['radius']:.3f}")
        
        return scene_info
        
    except Exception as e:
        print(f"SuperGlue SfM failed: {e}")
        import traceback
        traceback.print_exc()
        
        # ì‹¤íŒ¨ì‹œ fallback
        print("Falling back to simple camera arrangement...")
        return _create_fallback_scene_info(images_folder, max_images)


def _create_fallback_scene_info(images_folder, max_images):
    """ê°œì„ ëœ fallback scene ìƒì„±"""
    try:
        # ì´ë¯¸ì§€ ìˆ˜ì§‘
        image_paths = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:
            image_paths.extend(glob.glob(str(Path(images_folder) / ext)))
        
        image_paths.sort()
        image_paths = image_paths[:max_images]
        
        if not image_paths:
            raise ValueError(f"No images found in {images_folder}")
        
        print(f"ğŸ“¸ Found {len(image_paths)} images")
        
        # ì¹´ë©”ë¼ ì •ë³´ ìƒì„±
        cam_infos = []
        for i, image_path in enumerate(image_paths):
            try:
                # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
                image = Image.open(image_path)
                width, height = image.size
                
                # ì›í˜• ë°°ì¹˜ë¡œ ì¹´ë©”ë¼ ë°°ì¹˜
                angle = i * (2 * np.pi / len(image_paths))
                radius = 3.0
                
                # ì¹´ë©”ë¼ í¬ì¦ˆ (ì›ì„ ë°”ë¼ë³´ë„ë¡)
                camera_pos = np.array([
                    radius * np.cos(angle),
                    0.0,  # ë†’ì´ ê³ ì •
                    radius * np.sin(angle)
                ])
                
                # ì›ì ì„ í–¥í•˜ëŠ” ë°©í–¥
                look_at = np.array([0.0, 0.0, 0.0])
                up = np.array([0.0, 1.0, 0.0])
                
                # ì¹´ë©”ë¼ íšŒì „ í–‰ë ¬ ê³„ì‚°
                forward = look_at - camera_pos
                forward = forward / np.linalg.norm(forward)
                right = np.cross(forward, up)
                right = right / np.linalg.norm(right)
                up = np.cross(right, forward)
                
                R = np.array([right, up, -forward]).T  # OpenCV ì»¨ë²¤ì…˜
                T = camera_pos
                
                # FOV ê³„ì‚° (ë” ì•ˆì „í•œ ê°’ë“¤)
                focal_length = max(width, height) * 0.8
                FovX = 2 * np.arctan(width / (2 * focal_length))
                FovY = 2 * np.arctan(height / (2 * focal_length))
                
                # í…ŒìŠ¤íŠ¸ ì¹´ë©”ë¼ ì„ íƒ (ë” ê· ë“±í•˜ê²Œ ë¶„ì‚°)
                is_test = (i % 8 == 0)  # 8ê°œë§ˆë‹¤ 1ê°œì”© í…ŒìŠ¤íŠ¸
                
                cam_info = CameraInfo(
                    uid=i,
                    R=R.astype(np.float32),
                    T=T.astype(np.float32),
                    FovY=float(FovY),
                    FovX=float(FovX),
                    image_path=image_path,
                    image_name=Path(image_path).name,
                    width=int(width),
                    height=int(height),
                    depth_params=None,
                    depth_path="",
                    is_test=is_test
                )
                cam_infos.append(cam_info)
                
            except Exception as e:
                print(f"    Warning: Failed to process {image_path}: {e}")
                continue
        
        if not cam_infos:
            raise ValueError("No valid cameras created")
        
        # ê°œì„ ëœ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ìƒì„±
        n_points = 12000  # 8000 â†’ 12000ë¡œ ì¦ê°€
        
        # ë” í˜„ì‹¤ì ì¸ 3D í¬ì¸íŠ¸ ë¶„í¬
        # êµ¬í˜• ë¶„í¬ + ì¼ë¶€ í‰ë©´ êµ¬ì¡°
        points_sphere = np.random.randn(n_points // 2, 3).astype(np.float32)
        points_sphere = points_sphere / np.linalg.norm(points_sphere, axis=1, keepdims=True) * 3.0  # 2.0 â†’ 3.0
        
        # í‰ë©´ êµ¬ì¡° ì¶”ê°€ (ë°”ë‹¥ë©´)
        points_plane = np.random.randn(n_points // 2, 3).astype(np.float32)
        points_plane[:, 1] = np.abs(points_plane[:, 1]) * 0.2 - 1.0  # ë°”ë‹¥ ê·¼ì²˜ (0.1 â†’ 0.2, -0.5 â†’ -1.0)
        points_plane[:, [0, 2]] *= 2.0  # 1.5 â†’ 2.0
        
        points = np.vstack([points_sphere, points_plane])
        
        # ë” í˜„ì‹¤ì ì¸ ìƒ‰ìƒ (íšŒìƒ‰ì¡° + ì•½ê°„ì˜ ìƒ‰ìƒ)
        colors = np.random.rand(n_points, 3).astype(np.float32)
        colors = colors * 0.5 + 0.3  # 0.3-0.8 ë²”ìœ„
        
        # ë²•ì„  ë²¡í„° (ë¬´ì‘ìœ„ì§€ë§Œ ì •ê·œí™”ë¨)
        normals = np.random.randn(n_points, 3).astype(np.float32)
        normals = normals / (np.linalg.norm(normals, axis=1, keepdims=True) + 1e-10)
        
        # BasicPointCloud ìƒì„± ì‹œ ì°¨ì› í™•ì¸
        assert points.shape == (n_points, 3), f"Points shape error: {points.shape}"
        assert colors.shape == (n_points, 3), f"Colors shape error: {colors.shape}"
        assert normals.shape == (n_points, 3), f"Normals shape error: {normals.shape}"
        
        pcd = BasicPointCloud(
            points=points,
            colors=colors,
            normals=normals
        )
        
        # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
        train_cams = [c for c in cam_infos if not c.is_test]
        test_cams = [c for c in cam_infos if c.is_test]
        
        # NeRF ì •ê·œí™” (ê°œì„ ëœ ë²„ì „)
        if train_cams:
            camera_centers = []
            for cam in train_cams:
                # ì¹´ë©”ë¼ ì¤‘ì‹¬ ê³„ì‚°
                center = -cam.R.T @ cam.T
                camera_centers.append(center)
            
            camera_centers = np.array(camera_centers)
            scene_center = np.mean(camera_centers, axis=0)
            distances = np.linalg.norm(camera_centers - scene_center, axis=1)
            scene_radius = np.max(distances) * 1.2
            
            # ìµœì†Œ/ìµœëŒ€ ì œí•œ
            scene_radius = max(scene_radius, 1.0)
            scene_radius = min(scene_radius, 10.0)
        else:
            scene_center = np.zeros(3)
            scene_radius = 3.0
        
        nerf_normalization = {
            "translate": -scene_center.astype(np.float32),
            "radius": float(scene_radius)
        }
        
        scene_info = SceneInfo(
            point_cloud=pcd,
            train_cameras=train_cams,
            test_cameras=test_cams,
            nerf_normalization=nerf_normalization,
            ply_path="",
            is_nerf_synthetic=False
        )
        
        print(f"âœ“ Fallback scene created:")
        print(f"  - {len(train_cams)} training cameras")
        print(f"  - {len(test_cams)} test cameras")
        print(f"  - {n_points} 3D points")
        print(f"  - Scene radius: {scene_radius:.2f}")
        
        return scene_info
        
    except Exception as e:
        print(f"Failed to create fallback scene: {e}")
        raise


# ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤
def main():
    """ëª…ë ¹ì¤„ì—ì„œ SuperGlue 3DGS íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description="SuperGlue 3DGS Pipeline")
    parser.add_argument("--input", "-i", required=True, 
                       help="Input images directory")
    parser.add_argument("--output", "-o", required=True,
                       help="Output directory for 3DGS training")
    parser.add_argument("--max_images", type=int, default=100,
                       help="Maximum number of images to process")
    parser.add_argument("--config", choices=["indoor", "outdoor"], 
                       default="outdoor", help="SuperGlue configuration")
    parser.add_argument("--device", default="cuda", 
                       help="Device to use (cuda/cpu)")
    
    args = parser.parse_args()
    
    # SuperGlue ì„¤ì •
    config = {
        'superpoint': {
            'nms_radius': 3,  # 4 â†’ 3ìœ¼ë¡œ ì™„í™”
            'keypoint_threshold': 0.001,  # 0.005 â†’ 0.001ë¡œ ëŒ€í­ ì™„í™”
            'max_keypoints': 8192  # 4096 â†’ 8192ë¡œ ì¦ê°€
        },
        'superglue': {
            'weights': args.config,
            'sinkhorn_iterations': 15,  # 20 â†’ 15ë¡œ ì™„í™”
            'match_threshold': 0.05,  # 0.1 â†’ 0.05ë¡œ ì™„í™”
        }
    }
    
    print(f"=== SuperGlue 3DGS Pipeline ===")
    print(f"Input: {args.input}")
    print(f"Output: {args.output}")
    print(f"Max images: {args.max_images}")
    print(f"Config: {args.config}")
    print(f"Device: {args.device}")
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = SuperGlue3DGSPipeline(config, device=args.device)
    
    try:
        scene_info = pipeline.process_images_to_3dgs(
            image_dir=args.input,
            output_dir=args.output,
            max_images=args.max_images
        )
        
        print(f"\n=== Success! ===")
        print(f"Processed {len(scene_info.train_cameras)} training cameras")
        print(f"Generated {len(scene_info.point_cloud.points)} 3D points")
        print(f"Files saved to: {args.output}")
        print(f"\nNext step:")
        print(f"python train.py -s {args.output} -m {args.output}/3dgs_output")
        
    except Exception as e:
        print(f"\n=== Error! ===")
        print(f"Pipeline failed: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())